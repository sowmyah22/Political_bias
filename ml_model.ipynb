{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: logistic_regression\n",
      "Accuracy: 0.7405\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Center       0.93      0.81      0.87       686\n",
      "         Center-Right       0.00      0.00      0.00         0\n",
      "          Center/Left       0.00      0.00      0.00         0\n",
      " Center/Slightly Left       0.00      0.00      0.00         0\n",
      "Center/Slightly Right       0.00      0.00      0.00         2\n",
      "        Extreme Right       0.00      0.00      0.00         3\n",
      "                Right       0.00      0.00      0.00         5\n",
      "      Slightly Center       0.10      0.25      0.14         4\n",
      "        Slightly Left       0.36      0.48      0.41        73\n",
      "       Slightly Right       0.26      0.45      0.33        67\n",
      "\n",
      "             accuracy                           0.74       840\n",
      "            macro avg       0.16      0.20      0.17       840\n",
      "         weighted avg       0.81      0.74      0.77       840\n",
      "\n",
      "Training time: 0.85s\n",
      "\n",
      "Training model: linear_svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8131\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Center       0.89      0.93      0.91       686\n",
      "         Center-Right       0.00      0.00      0.00         0\n",
      " Center/Slightly Left       0.00      0.00      0.00         0\n",
      "Center/Slightly Right       0.00      0.00      0.00         2\n",
      "        Extreme Right       0.00      0.00      0.00         3\n",
      "                Right       0.00      0.00      0.00         5\n",
      "      Slightly Center       0.00      0.00      0.00         4\n",
      "        Slightly Left       0.49      0.33      0.39        73\n",
      "       Slightly Right       0.37      0.33      0.35        67\n",
      "\n",
      "             accuracy                           0.81       840\n",
      "            macro avg       0.19      0.18      0.18       840\n",
      "         weighted avg       0.80      0.81      0.80       840\n",
      "\n",
      "Training time: 0.60s\n",
      "\n",
      "Training model: random_forest\n",
      "Accuracy: 0.7560\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Center       0.83      0.90      0.86       686\n",
      " Center/Slightly Left       0.00      0.00      0.00         0\n",
      "Center/Slightly Right       0.00      0.00      0.00         2\n",
      "        Extreme Right       0.00      0.00      0.00         3\n",
      "                Right       0.00      0.00      0.00         5\n",
      "      Slightly Center       0.00      0.00      0.00         4\n",
      "        Slightly Left       0.73      0.11      0.19        73\n",
      "       Slightly Right       0.31      0.19      0.24        67\n",
      "\n",
      "             accuracy                           0.76       840\n",
      "            macro avg       0.23      0.15      0.16       840\n",
      "         weighted avg       0.77      0.76      0.74       840\n",
      "\n",
      "Training time: 15.38s\n",
      "\n",
      "Best model selected: linear_svm (Accuracy: 0.8131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: the_indian_express_analyzed_comparison.csv\n",
      "Saved pivot: the_indian_express_analyzed_pivot.csv\n",
      "Saved: ndtv_analyzed_comparison.csv\n",
      "Saved pivot: ndtv_analyzed_pivot.csv\n",
      "Saved: the_hindu_analyzed_comparison.csv\n",
      "Saved pivot: the_hindu_analyzed_pivot.csv\n",
      "Saved: news18_analyzed_comparison.csv\n",
      "Saved pivot: news18_analyzed_pivot.csv\n",
      "Saved: times_of_india_analyzed_comparison.csv\n",
      "Saved pivot: times_of_india_analyzed_pivot.csv\n",
      "Saved: zee_news_analyzed_comparison.csv\n",
      "Saved pivot: zee_news_analyzed_pivot.csv\n",
      "Saved: india_today_analyzed_comparison.csv\n",
      "Saved pivot: india_today_analyzed_pivot.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# Paths\n",
    "json_dir = \"dl_data-main/analyzed_articles/llama3_8b\"\n",
    "output_dir = \"dl_data-main/analyzed_articles/ml_model\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "all_data = []\n",
    "\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(json_dir, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            try:\n",
    "                file_data = json.load(f)\n",
    "                all_data.extend(file_data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# --- Normalize 'analysis' field ---\n",
    "if 'analysis' in df.columns:\n",
    "    analysis_df = pd.json_normalize(df['analysis'])\n",
    "    df = pd.concat([df.drop(columns=['analysis']), analysis_df], axis=1)\n",
    "\n",
    "# Preprocess\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.lower()\n",
    "    elif isinstance(text, list):\n",
    "        return \" \".join(str(item).lower() for item in text)\n",
    "    else:\n",
    "        return str(text).lower()\n",
    "\n",
    "for col in ['source', 'title', 'text', 'keywords']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(preprocess_text)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df['text'].astype(str))\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['bias_category'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"linear_svm\": LinearSVC(class_weight=\"balanced\"),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining model: {name}\")\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    present_labels = unique_labels(y_test, preds)\n",
    "    present_names = label_encoder.inverse_transform(present_labels)\n",
    "    print(classification_report(y_test, preds, labels=present_labels, target_names=present_names))\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model = (name, model)\n",
    "    print(f\"Training time: {time.time() - start:.2f}s\")\n",
    "\n",
    "model_name, model = best_model\n",
    "print(f\"\\nBest model selected: {model_name} (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "# Rule-based Bias Detection\n",
    "bias_keywords_left = {\n",
    "    'extreme left': ['radical', 'communism', 'revolution', 'anarchy'],\n",
    "    'left': ['progressive', 'liberal', 'social justice', 'equality'],\n",
    "    'slightly left': ['democratic', 'equality', 'human rights', 'inclusive']\n",
    "}\n",
    "\n",
    "bias_keywords_right = {\n",
    "    'extreme right': ['fascism', 'authoritarian', 'nationalism', 'white supremacy'],\n",
    "    'right': ['conservative', 'traditional', 'patriot', 'family values'],\n",
    "    'slightly right': ['republican', 'libertarian', 'freedom', 'capitalism']\n",
    "}\n",
    "\n",
    "def detect_bias(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 'Center'\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    left_score = sum(any(word in words for word in kw) for kw in bias_keywords_left.values())\n",
    "    right_score = sum(any(word in words for word in kw) for kw in bias_keywords_right.values())\n",
    "\n",
    "    if left_score > right_score:\n",
    "        if left_score > 3: return 'Extreme Left'\n",
    "        elif left_score > 1: return 'Left'\n",
    "        else: return 'Slightly Left'\n",
    "    elif right_score > left_score:\n",
    "        if right_score > 3: return 'Extreme Right'\n",
    "        elif right_score > 1: return 'Right'\n",
    "        else: return 'Slightly Right'\n",
    "    else:\n",
    "        return 'Center'\n",
    "\n",
    "# Predict for all JSONs\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(json_dir, filename)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                articles = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        file_df = pd.DataFrame(articles)\n",
    "        if file_df.empty or 'text' not in file_df.columns:\n",
    "            continue\n",
    "\n",
    "        for col in ['source', 'title', 'text', 'keywords']:\n",
    "            if col in file_df.columns:\n",
    "                file_df[col] = file_df[col].apply(preprocess_text)\n",
    "\n",
    "        # TF-IDF transform and predict\n",
    "        X_file = vectorizer.transform(file_df['text'].astype(str))\n",
    "        pred_classes = model.predict(X_file)\n",
    "\n",
    "        # Rule-based prediction\n",
    "        file_df['predicted_bias_rule'] = file_df['text'].apply(detect_bias)\n",
    "\n",
    "        # Save comparison CSV\n",
    "        comparison_data = []\n",
    "        for i in range(len(file_df)):\n",
    "            article_id = f\"A{i+1:04d}\"\n",
    "            title = file_df.loc[i, 'title'] if 'title' in file_df.columns else ''\n",
    "            url = file_df.loc[i, 'url'] if 'url' in file_df.columns else ''\n",
    "            reasoning = file_df.loc[i, 'reasoning'] if 'reasoning' in file_df.columns else ''\n",
    "            predicted_bias = label_encoder.inverse_transform([pred_classes[i]])[0]\n",
    "            comparison_data.append({\n",
    "                'article_id': article_id,\n",
    "                'title': title,\n",
    "                'url': url,\n",
    "                'model': model_name,\n",
    "                'bias_category': predicted_bias,\n",
    "                'reasoning': reasoning\n",
    "            })\n",
    "\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_filename = filename.replace(\".json\", \"_comparison.csv\")\n",
    "        comparison_df.to_csv(os.path.join(output_dir, comparison_filename), index=False)\n",
    "        print(f\"Saved: {comparison_filename}\")\n",
    "\n",
    "        # Save pivot\n",
    "        pivot_df = comparison_df.pivot_table(\n",
    "            index=['article_id', 'title', 'url'],\n",
    "            columns='model',\n",
    "            values='bias_category',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        pivot_df.columns.name = None\n",
    "        pivot_filename = filename.replace(\".json\", \"_pivot.csv\")\n",
    "        pivot_df.to_csv(os.path.join(output_dir, pivot_filename), index=False)\n",
    "        print(f\"Saved pivot: {pivot_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Included sampling techniques(smote) and also added xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping SMOTE: smallest class has only 1 sample(s).\n",
      "\n",
      "Training model: logistic_regression\n",
      "Accuracy: 0.7393\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Center       0.93      0.81      0.87       686\n",
      "         Center-Right       0.00      0.00      0.00         0\n",
      "          Center/Left       0.00      0.00      0.00         0\n",
      " Center/Slightly Left       0.00      0.00      0.00         0\n",
      "Center/Slightly Right       0.00      0.00      0.00         2\n",
      "        Extreme Right       0.00      0.00      0.00         3\n",
      "                Right       0.00      0.00      0.00         5\n",
      "      Slightly Center       0.10      0.25      0.14         4\n",
      "        Slightly Left       0.35      0.48      0.41        73\n",
      "       Slightly Right       0.25      0.43      0.32        67\n",
      "\n",
      "             accuracy                           0.74       840\n",
      "            macro avg       0.16      0.20      0.17       840\n",
      "         weighted avg       0.81      0.74      0.77       840\n",
      "\n",
      "Training time: 0.76s\n",
      "\n",
      "Training model: linear_svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8143\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Center       0.89      0.93      0.91       686\n",
      "         Center-Right       0.00      0.00      0.00         0\n",
      " Center/Slightly Left       0.00      0.00      0.00         0\n",
      "Center/Slightly Right       0.00      0.00      0.00         2\n",
      "        Extreme Right       0.00      0.00      0.00         3\n",
      "                Right       0.00      0.00      0.00         5\n",
      "      Slightly Center       0.00      0.00      0.00         4\n",
      "        Slightly Left       0.50      0.33      0.40        73\n",
      "       Slightly Right       0.37      0.33      0.35        67\n",
      "\n",
      "             accuracy                           0.81       840\n",
      "            macro avg       0.20      0.18      0.18       840\n",
      "         weighted avg       0.80      0.81      0.81       840\n",
      "\n",
      "Training time: 0.62s\n",
      "\n",
      "Training model: random_forest\n",
      "Accuracy: 0.7548\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Center       0.83      0.89      0.86       686\n",
      " Center/Slightly Left       0.00      0.00      0.00         0\n",
      "Center/Slightly Right       0.00      0.00      0.00         2\n",
      "        Extreme Right       0.00      0.00      0.00         3\n",
      "                Right       0.00      0.00      0.00         5\n",
      "      Slightly Center       0.00      0.00      0.00         4\n",
      "        Slightly Left       0.73      0.11      0.19        73\n",
      "       Slightly Right       0.30      0.19      0.24        67\n",
      "\n",
      "             accuracy                           0.75       840\n",
      "            macro avg       0.23      0.15      0.16       840\n",
      "         weighted avg       0.76      0.75      0.74       840\n",
      "\n",
      "Training time: 16.24s\n",
      "\n",
      "Training model: xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:25:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8369\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "               Center       0.86      0.98      0.91       686\n",
      "Center/Slightly Right       0.00      0.00      0.00         2\n",
      "        Extreme Right       0.00      0.00      0.00         3\n",
      "                Right       0.00      0.00      0.00         5\n",
      "      Slightly Center       0.00      0.00      0.00         4\n",
      "        Slightly Left       0.63      0.23      0.34        73\n",
      "       Slightly Right       0.52      0.21      0.30        67\n",
      "\n",
      "             accuracy                           0.84       840\n",
      "            macro avg       0.29      0.20      0.22       840\n",
      "         weighted avg       0.80      0.84      0.80       840\n",
      "\n",
      "Training time: 48.40s\n",
      "\n",
      "Best model selected: xgboost (Accuracy: 0.8369)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: the_indian_express_analyzed_comparison.csv\n",
      "Saved pivot: the_indian_express_analyzed_pivot.csv\n",
      "Saved: ndtv_analyzed_comparison.csv\n",
      "Saved pivot: ndtv_analyzed_pivot.csv\n",
      "Saved: the_hindu_analyzed_comparison.csv\n",
      "Saved pivot: the_hindu_analyzed_pivot.csv\n",
      "Saved: news18_analyzed_comparison.csv\n",
      "Saved pivot: news18_analyzed_pivot.csv\n",
      "Saved: times_of_india_analyzed_comparison.csv\n",
      "Saved pivot: times_of_india_analyzed_pivot.csv\n",
      "Saved: zee_news_analyzed_comparison.csv\n",
      "Saved pivot: zee_news_analyzed_pivot.csv\n",
      "Saved: india_today_analyzed_comparison.csv\n",
      "Saved pivot: india_today_analyzed_pivot.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "json_dir = \"dl_data-main/analyzed_articles/llama3_8b\"\n",
    "output_dir = \"dl_data-main/ml_model\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "all_data = []\n",
    "\n",
    "# Load and preprocess data\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(json_dir, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            try:\n",
    "                file_data = json.load(f)\n",
    "                all_data.extend(file_data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# --- Normalize 'analysis' field ---\n",
    "if 'analysis' in df.columns:\n",
    "    analysis_df = pd.json_normalize(df['analysis'])\n",
    "    df = pd.concat([df.drop(columns=['analysis']), analysis_df], axis=1)\n",
    "\n",
    "# Preprocess text columns\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.lower()\n",
    "    elif isinstance(text, list):\n",
    "        return \" \".join(str(item).lower() for item in text)\n",
    "    else:\n",
    "        return str(text).lower()\n",
    "\n",
    "for col in ['source', 'title', 'text', 'keywords']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(preprocess_text)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df['text'].astype(str))\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['bias_category'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE Resampling (with safeguards for small classes\n",
    "# Check class distribution\n",
    "class_counts = Counter(y_train)\n",
    "min_class_size = min(class_counts.values())\n",
    "\n",
    "if min_class_size <= 1:\n",
    "    print(f\"⚠️ Skipping SMOTE: smallest class has only {min_class_size} sample(s).\")\n",
    "    X_train_resampled, y_train_resampled = X_train, y_train\n",
    "else:\n",
    "    # Dynamically set k_neighbors\n",
    "    k_neighbors = min(5, min_class_size - 1)\n",
    "    print(f\"Applying SMOTE with k_neighbors={k_neighbors}\")\n",
    "    smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# # SMOTE Resampling\n",
    "# smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"linear_svm\": LinearSVC(class_weight=\"balanced\"),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=200, class_weight=\"balanced\"),\n",
    "    \"xgboost\": XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining model: {name}\")\n",
    "    start = time.time()\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    present_labels = unique_labels(y_test, preds)\n",
    "    present_names = label_encoder.inverse_transform(present_labels)\n",
    "    print(classification_report(y_test, preds, labels=present_labels, target_names=present_names))\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model = (name, model)\n",
    "    print(f\"Training time: {time.time() - start:.2f}s\")\n",
    "\n",
    "model_name, model = best_model\n",
    "print(f\"\\nBest model selected: {model_name} (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "# Rule-based Bias Detection\n",
    "bias_keywords_left = {\n",
    "    'extreme left': ['radical', 'communism', 'revolution', 'anarchy'],\n",
    "    'left': ['progressive', 'liberal', 'social justice', 'equality'],\n",
    "    'slightly left': ['democratic', 'equality', 'human rights', 'inclusive']\n",
    "}\n",
    "\n",
    "bias_keywords_right = {\n",
    "    'extreme right': ['fascism', 'authoritarian', 'nationalism', 'white supremacy'],\n",
    "    'right': ['conservative', 'traditional', 'patriot', 'family values'],\n",
    "    'slightly right': ['republican', 'libertarian', 'freedom', 'capitalism']\n",
    "}\n",
    "\n",
    "def detect_bias(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 'Center'\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    left_score = sum(any(word in words for word in kw) for kw in bias_keywords_left.values())\n",
    "    right_score = sum(any(word in words for word in kw) for kw in bias_keywords_right.values())\n",
    "\n",
    "    if left_score > right_score:\n",
    "        if left_score > 3: return 'Extreme Left'\n",
    "        elif left_score > 1: return 'Left'\n",
    "        else: return 'Slightly Left'\n",
    "    elif right_score > left_score:\n",
    "        if right_score > 3: return 'Extreme Right'\n",
    "        elif right_score > 1: return 'Right'\n",
    "        else: return 'Slightly Right'\n",
    "    else:\n",
    "        return 'Center'\n",
    "\n",
    "# Predict for all JSONs and generate results\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(json_dir, filename)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                articles = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        file_df = pd.DataFrame(articles)\n",
    "        if file_df.empty or 'text' not in file_df.columns:\n",
    "            continue\n",
    "\n",
    "        for col in ['source', 'title', 'text', 'keywords']:\n",
    "            if col in file_df.columns:\n",
    "                file_df[col] = file_df[col].apply(preprocess_text)\n",
    "\n",
    "        # TF-IDF transform and predict\n",
    "        X_file = vectorizer.transform(file_df['text'].astype(str))\n",
    "        pred_classes = model.predict(X_file)\n",
    "\n",
    "        # Rule-based prediction\n",
    "        file_df['predicted_bias_rule'] = file_df['text'].apply(detect_bias)\n",
    "\n",
    "        # Save comparison CSV\n",
    "        comparison_data = []\n",
    "        for i in range(len(file_df)):\n",
    "            article_id = f\"A{i+1:04d}\"\n",
    "            title = file_df.loc[i, 'title'] if 'title' in file_df.columns else ''\n",
    "            url = file_df.loc[i, 'url'] if 'url' in file_df.columns else ''\n",
    "            reasoning = file_df.loc[i, 'reasoning'] if 'reasoning' in file_df.columns else ''\n",
    "            predicted_bias = label_encoder.inverse_transform([pred_classes[i]])[0]\n",
    "            comparison_data.append({\n",
    "                'article_id': article_id,\n",
    "                'title': title,\n",
    "                'url': url,\n",
    "                'model': model_name,\n",
    "                'bias_category': predicted_bias,\n",
    "                'reasoning': reasoning\n",
    "            })\n",
    "\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_filename = filename.replace(\".json\", \"_comparison.csv\")\n",
    "        comparison_df.to_csv(os.path.join(output_dir, comparison_filename), index=False)\n",
    "        print(f\"Saved: {comparison_filename}\")\n",
    "\n",
    "        # Save pivot\n",
    "        pivot_df = comparison_df.pivot_table(\n",
    "            index=['article_id', 'title', 'url'],\n",
    "            columns='model',\n",
    "            values='bias_category',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        pivot_df.columns.name = None\n",
    "        pivot_filename = filename.replace(\".json\", \"_pivot.csv\")\n",
    "        pivot_df.to_csv(os.path.join(output_dir, pivot_filename), index=False)\n",
    "        print(f\"Saved pivot: {pivot_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
