{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfsGulyiAxIH",
        "outputId": "76d6c2a7-0d49-4092-f165-7f54a2110dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iQBXKhWuExWA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from functools import lru_cache\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tveNB9V4My7c",
        "outputId": "843a3f05-60e8-4d44-8def-c3a8940be784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Would remove:\n",
            "    /usr/local/bin/torchfrtrace\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.11/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch-2.6.0+cu124.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision-0.21.0+cu124.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libcudart.41118559.so.12\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libjpeg.1c1c4b09.so.8\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libnvjpeg.02b6d700.so.12\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libpng16.0364a1db.so.16\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libsharpyuv.5c41a003.so.0\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libwebp.54a0d02a.so.7\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libz.d13a2644.so.1\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/torchaudio-2.6.0+cu124.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchaudio/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torio/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "O-2QrU9TE88l",
        "outputId": "b6783374-77b3-4172-c24f-608f76b06ed5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at launch/politics and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1900' max='17130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1900/17130 16:15 < 2:10:30, 1.94 it/s, Epoch 0/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Left</th>\n",
              "      <th>F1 Center</th>\n",
              "      <th>F1 Right</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.043500</td>\n",
              "      <td>0.924291</td>\n",
              "      <td>0.572584</td>\n",
              "      <td>0.548423</td>\n",
              "      <td>0.599522</td>\n",
              "      <td>0.572584</td>\n",
              "      <td>0.384361</td>\n",
              "      <td>0.699527</td>\n",
              "      <td>0.561381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.783200</td>\n",
              "      <td>0.713777</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.684144</td>\n",
              "      <td>0.701784</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.564830</td>\n",
              "      <td>0.801613</td>\n",
              "      <td>0.685988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.614000</td>\n",
              "      <td>0.519830</td>\n",
              "      <td>0.797361</td>\n",
              "      <td>0.797069</td>\n",
              "      <td>0.797081</td>\n",
              "      <td>0.797361</td>\n",
              "      <td>0.754173</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.766445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.542600</td>\n",
              "      <td>0.451299</td>\n",
              "      <td>0.832354</td>\n",
              "      <td>0.828858</td>\n",
              "      <td>0.842737</td>\n",
              "      <td>0.832354</td>\n",
              "      <td>0.781986</td>\n",
              "      <td>0.868020</td>\n",
              "      <td>0.836570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.354838</td>\n",
              "      <td>0.873904</td>\n",
              "      <td>0.871937</td>\n",
              "      <td>0.880865</td>\n",
              "      <td>0.873904</td>\n",
              "      <td>0.836094</td>\n",
              "      <td>0.908455</td>\n",
              "      <td>0.871263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.331500</td>\n",
              "      <td>0.275846</td>\n",
              "      <td>0.907876</td>\n",
              "      <td>0.907486</td>\n",
              "      <td>0.908493</td>\n",
              "      <td>0.907876</td>\n",
              "      <td>0.889524</td>\n",
              "      <td>0.928124</td>\n",
              "      <td>0.904812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.358900</td>\n",
              "      <td>0.278915</td>\n",
              "      <td>0.907961</td>\n",
              "      <td>0.906955</td>\n",
              "      <td>0.914575</td>\n",
              "      <td>0.907961</td>\n",
              "      <td>0.874141</td>\n",
              "      <td>0.949310</td>\n",
              "      <td>0.897415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.244900</td>\n",
              "      <td>0.215478</td>\n",
              "      <td>0.934951</td>\n",
              "      <td>0.934743</td>\n",
              "      <td>0.935652</td>\n",
              "      <td>0.934951</td>\n",
              "      <td>0.928516</td>\n",
              "      <td>0.946680</td>\n",
              "      <td>0.929034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.228200</td>\n",
              "      <td>0.151189</td>\n",
              "      <td>0.955981</td>\n",
              "      <td>0.955877</td>\n",
              "      <td>0.956363</td>\n",
              "      <td>0.955981</td>\n",
              "      <td>0.948852</td>\n",
              "      <td>0.963380</td>\n",
              "      <td>0.955399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.243500</td>\n",
              "      <td>0.145883</td>\n",
              "      <td>0.962112</td>\n",
              "      <td>0.962121</td>\n",
              "      <td>0.962167</td>\n",
              "      <td>0.962112</td>\n",
              "      <td>0.957074</td>\n",
              "      <td>0.967791</td>\n",
              "      <td>0.961499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>0.131163</td>\n",
              "      <td>0.965858</td>\n",
              "      <td>0.965825</td>\n",
              "      <td>0.966293</td>\n",
              "      <td>0.965858</td>\n",
              "      <td>0.963048</td>\n",
              "      <td>0.969250</td>\n",
              "      <td>0.965177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.144700</td>\n",
              "      <td>0.122253</td>\n",
              "      <td>0.968157</td>\n",
              "      <td>0.968145</td>\n",
              "      <td>0.968287</td>\n",
              "      <td>0.968157</td>\n",
              "      <td>0.964706</td>\n",
              "      <td>0.974411</td>\n",
              "      <td>0.965316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.218000</td>\n",
              "      <td>0.113251</td>\n",
              "      <td>0.969093</td>\n",
              "      <td>0.969127</td>\n",
              "      <td>0.969381</td>\n",
              "      <td>0.969093</td>\n",
              "      <td>0.973495</td>\n",
              "      <td>0.969237</td>\n",
              "      <td>0.964650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.138600</td>\n",
              "      <td>0.105122</td>\n",
              "      <td>0.973350</td>\n",
              "      <td>0.973385</td>\n",
              "      <td>0.974147</td>\n",
              "      <td>0.973350</td>\n",
              "      <td>0.973746</td>\n",
              "      <td>0.970661</td>\n",
              "      <td>0.975748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.139700</td>\n",
              "      <td>0.094206</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>0.978198</td>\n",
              "      <td>0.978442</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>0.977076</td>\n",
              "      <td>0.978332</td>\n",
              "      <td>0.979185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.118900</td>\n",
              "      <td>0.083952</td>\n",
              "      <td>0.980332</td>\n",
              "      <td>0.980343</td>\n",
              "      <td>0.980640</td>\n",
              "      <td>0.980332</td>\n",
              "      <td>0.981997</td>\n",
              "      <td>0.979628</td>\n",
              "      <td>0.979404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.137600</td>\n",
              "      <td>0.069326</td>\n",
              "      <td>0.985355</td>\n",
              "      <td>0.985365</td>\n",
              "      <td>0.985439</td>\n",
              "      <td>0.985355</td>\n",
              "      <td>0.987433</td>\n",
              "      <td>0.982896</td>\n",
              "      <td>0.985767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>0.072408</td>\n",
              "      <td>0.984845</td>\n",
              "      <td>0.984850</td>\n",
              "      <td>0.984956</td>\n",
              "      <td>0.984845</td>\n",
              "      <td>0.986220</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>0.984021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.126700</td>\n",
              "      <td>0.080917</td>\n",
              "      <td>0.978714</td>\n",
              "      <td>0.978686</td>\n",
              "      <td>0.978977</td>\n",
              "      <td>0.978714</td>\n",
              "      <td>0.976962</td>\n",
              "      <td>0.983544</td>\n",
              "      <td>0.975553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='368' max='368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [368/368 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 2447/2447 [02:09<00:00, 18.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final results: {'eval_loss': 0.05405449494719505, 'eval_accuracy': 0.9891868880374628, 'eval_f1': 0.9891894577044392, 'eval_precision': 0.9892285941578098, 'eval_recall': 0.9891868880374628, 'eval_f1_left': 0.9905346635968278, 'eval_f1_center': 0.9880650076180802, 'eval_f1_right': 0.9889687018984095, 'eval_runtime': 18.7003, 'eval_samples_per_second': 628.065, 'eval_steps_per_second': 19.679, 'epoch': 0.5545826036193812}\n"
          ]
        }
      ],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "MODEL_NAME = \"launch/politics\"  # Original specialized political bias model\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/soumya/results\"\n",
        "LOGGING_DIR = \"/content/drive/MyDrive/soumya/logs\"\n",
        "RESULTS_PATH = \"/content/drive/MyDrive/soumya/results/predictions.csv\"\n",
        "CACHE_DIR = \"/content/drive/MyDrive/soumya/results/cache\"  # Add cache directory to prevent redownloading\n",
        "DATASET_CACHE_DIR = \"/content/drive/MyDrive/soumya/result/dataset_cache\"  # Cache processed datasets\n",
        "\n",
        "# Ensure directories exist\n",
        "for directory in [OUTPUT_DIR, LOGGING_DIR, CACHE_DIR, DATASET_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Set device and optimize memory usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "# Optimize memory usage based on available hardware\n",
        "def optimize_memory():\n",
        "    \"\"\"Configure memory optimizations based on available hardware.\"\"\"\n",
        "    config = {\n",
        "        \"batch_size\": 8,\n",
        "        \"eval_batch_size\": 16,\n",
        "        \"num_workers\": min(os.cpu_count() - 1, 4) if os.cpu_count() > 1 else 0,\n",
        "        \"gradient_accumulation_steps\": 2,\n",
        "        \"mixed_precision\": False\n",
        "    }\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        # Print GPU info\n",
        "        logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        logger.info(f\"GPU Memory: {total_memory:.2f} GB\")\n",
        "\n",
        "        # Empty GPU cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Adjust settings based on available GPU memory\n",
        "        if total_memory > 10:  # High-end GPU\n",
        "            config[\"batch_size\"] = 16\n",
        "            config[\"eval_batch_size\"] = 32\n",
        "            config[\"gradient_accumulation_steps\"] = 1\n",
        "        elif total_memory < 4:  # Low memory GPU\n",
        "            config[\"batch_size\"] = 4\n",
        "            config[\"eval_batch_size\"] = 8\n",
        "            config[\"gradient_accumulation_steps\"] = 4\n",
        "\n",
        "        config[\"mixed_precision\"] = True\n",
        "\n",
        "    return config\n",
        "\n",
        "memory_config = optimize_memory()\n",
        "\n",
        "# ---------------- Text Processing Functions ----------------\n",
        "@lru_cache(maxsize=1024)  # Cache preprocessed texts to avoid repeated processing\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and preprocess text.\"\"\"\n",
        "    if pd.isna(text) or text is None:\n",
        "        return \"\"\n",
        "    if isinstance(text, list):\n",
        "        return ' '.join(str(t).lower().strip() for t in text if isinstance(t, str))\n",
        "    return str(text).lower().strip()\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    \"\"\"Combine multiple text columns into one, efficiently.\"\"\"\n",
        "    # Process each column once\n",
        "    processed_cols = {}\n",
        "    for col in text_cols:\n",
        "        if col in df.columns:\n",
        "            processed_cols[col] = df[col].apply(preprocess_text)\n",
        "        else:\n",
        "            processed_cols[col] = pd.Series([\"\"] * len(df))\n",
        "\n",
        "    # Combine processed columns efficiently\n",
        "    combined_series = processed_cols[text_cols[0]].copy()\n",
        "    for col in text_cols[1:]:\n",
        "        # Only concatenate non-empty strings\n",
        "        mask = processed_cols[col] != \"\"\n",
        "        combined_series[mask] = combined_series[mask] + \" \" + processed_cols[col][mask]\n",
        "\n",
        "    return combined_series\n",
        "\n",
        "def create_data_from_batch(batch_df, tokenizer, max_length=128):\n",
        "    \"\"\"Process a batch of data into features suitable for model input.\"\"\"\n",
        "    texts = batch_df[\"combined_input\"].tolist()\n",
        "\n",
        "    # Efficient tokenization with padding to max length in batch\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Create labels tensor if available\n",
        "    labels = None\n",
        "    if \"label\" in batch_df:\n",
        "        labels = torch.tensor(batch_df[\"label\"].tolist())\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": encodings[\"input_ids\"],\n",
        "        \"attention_mask\": encodings[\"attention_mask\"],\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "# ---------------- Load and Process Data ----------------\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load and perform initial data processing.\"\"\"\n",
        "    cache_file = os.path.join(DATASET_CACHE_DIR, f\"{os.path.basename(file_path)}.processed.pkl\")\n",
        "\n",
        "    # Check if processed data exists in cache\n",
        "    if os.path.exists(cache_file):\n",
        "        logger.info(f\"Loading processed data from cache: {cache_file}\")\n",
        "        return pd.read_pickle(cache_file)\n",
        "\n",
        "    logger.info(\"Loading and processing data\")\n",
        "    try:\n",
        "        if file_path.endswith('.xlsx'):\n",
        "            df = pd.read_excel(file_path, engine='openpyxl')\n",
        "        elif file_path.endswith('.csv'):\n",
        "            df = pd.read_csv(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading data: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Filter data\n",
        "    df = df[df[\"type\"].isin(LABEL_MAP.keys())]\n",
        "\n",
        "    logger.info(\"Class distribution:\")\n",
        "    logger.info(df[\"type\"].value_counts())\n",
        "\n",
        "    # Process text columns more efficiently\n",
        "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
        "    df[\"combined_input\"] = combine_text(df, text_cols)\n",
        "    df[\"label\"] = df[\"type\"].map(LABEL_MAP)\n",
        "\n",
        "    # Cache the processed data\n",
        "    df.to_pickle(cache_file)\n",
        "    logger.info(f\"Processed data cached to: {cache_file}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ---------------- Dataset Classes ----------------\n",
        "class PoliticalBiasDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Custom dataset for efficient batch processing.\"\"\"\n",
        "    def __init__(self, df, tokenizer, max_length=128):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.has_labels = \"label\" in df.columns\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\"combined_input\": self.df.iloc[idx][\"combined_input\"]}\n",
        "        if self.has_labels:\n",
        "            item[\"label\"] = self.df.iloc[idx][\"label\"]\n",
        "        return item\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Custom collate function for efficient batching.\"\"\"\n",
        "        batch_df = pd.DataFrame(batch)\n",
        "        return create_data_from_batch(batch_df, self.tokenizer, self.max_length)\n",
        "\n",
        "# ---------------- Metrics ----------------\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute evaluation metrics.\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Detailed report\n",
        "    class_report = classification_report(labels, preds, target_names=LABEL_MAP.keys(), output_dict=True)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "    # Add class-specific metrics\n",
        "    for cls in LABEL_MAP.keys():\n",
        "        metrics[f\"f1_{cls}\"] = class_report[cls]['f1-score']\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# ---------------- Main Pipeline ----------------\n",
        "def main(file_path):\n",
        "    \"\"\"Main training and evaluation pipeline.\"\"\"\n",
        "    logger.info(\"Starting main pipeline\")\n",
        "\n",
        "    # Load and prepare data\n",
        "    df = load_data(file_path)\n",
        "\n",
        "    # Train-Test Split\n",
        "    logger.info(\"Splitting data\")\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df[\"label\"], random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
        "\n",
        "    logger.info(f\"Train set: {len(train_df)} samples\")\n",
        "    logger.info(f\"Validation set: {len(val_df)} samples\")\n",
        "    logger.info(f\"Test set: {len(test_df)} samples\")\n",
        "\n",
        "    # Load Tokenizer and Model\n",
        "    logger.info(f\"Loading tokenizer and model: {MODEL_NAME}\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            num_labels=len(LABEL_MAP),\n",
        "            cache_dir=CACHE_DIR,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading model {MODEL_NAME}: {e}\")\n",
        "        logger.info(\"Attempting to use fallback model\")\n",
        "        fallback_model = \"distilbert-base-uncased\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(fallback_model, cache_dir=CACHE_DIR)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            fallback_model,\n",
        "            num_labels=len(LABEL_MAP),\n",
        "            cache_dir=CACHE_DIR\n",
        "        )\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "        logger.info(f\"Fallback model {fallback_model} loaded successfully\")\n",
        "\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "\n",
        "    # Create custom datasets for memory efficiency\n",
        "    train_dataset = PoliticalBiasDataset(train_df, tokenizer)\n",
        "    val_dataset = PoliticalBiasDataset(val_df, tokenizer)\n",
        "    test_dataset = PoliticalBiasDataset(test_df, tokenizer)\n",
        "\n",
        "    # Training Arguments\n",
        "    logger.info(\"Setting up training arguments\")\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        logging_dir=LOGGING_DIR,\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=100,\n",
        "        per_device_train_batch_size=memory_config[\"batch_size\"],\n",
        "        per_device_eval_batch_size=memory_config[\"eval_batch_size\"],\n",
        "        gradient_accumulation_steps=memory_config[\"gradient_accumulation_steps\"],\n",
        "        num_train_epochs=5,\n",
        "        learning_rate=2e-5,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        save_total_limit=2,\n",
        "        report_to=\"none\",\n",
        "        fp16=memory_config[\"mixed_precision\"],\n",
        "        dataloader_num_workers=memory_config[\"num_workers\"],\n",
        "        remove_unused_columns=False,  # We handle column selection in our dataset\n",
        "        disable_tqdm=False  # Show progress bar\n",
        "    )\n",
        "\n",
        "    # Custom data collator using our dataset's collate function\n",
        "    def collate_fn(batch):\n",
        "        return train_dataset.collate_fn(batch)\n",
        "\n",
        "    # Initialize Trainer\n",
        "    logger.info(\"Initializing Trainer\")\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=collate_fn,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    logger.info(\"Starting training\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Save model and tokenizer\n",
        "    logger.info(\"Saving model and tokenizer\")\n",
        "    model.save_pretrained(OUTPUT_DIR)\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "    logger.info(f\"Model and tokenizer saved to {OUTPUT_DIR}\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    logger.info(\"Evaluating on test set\")\n",
        "    test_results = trainer.evaluate(test_dataset)\n",
        "    logger.info(f\"Test results: {test_results}\")\n",
        "\n",
        "    # Make predictions in batches for memory efficiency\n",
        "    logger.info(\"Making predictions on all data\")\n",
        "    full_dataset = PoliticalBiasDataset(df[[\"combined_input\"]], tokenizer)\n",
        "\n",
        "    # Create a DataLoader for batch processing predictions\n",
        "    prediction_dataloader = torch.utils.data.DataLoader(\n",
        "        full_dataset,\n",
        "        batch_size=memory_config[\"eval_batch_size\"],\n",
        "        collate_fn=full_dataset.collate_fn,\n",
        "        num_workers=memory_config[\"num_workers\"],\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Make predictions in batches\n",
        "    all_predictions = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(prediction_dataloader, desc=\"Predicting\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            all_predictions.extend(batch_preds)\n",
        "\n",
        "    # Save predictions\n",
        "    df[\"predicted_bias_category\"] = [REVERSE_LABEL_MAP[i] for i in all_predictions]\n",
        "    df.to_csv(RESULTS_PATH, index=False)\n",
        "    logger.info(f\"Predictions saved to {RESULTS_PATH}\")\n",
        "\n",
        "    # Clean up GPU memory\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return test_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file_path = \"/content/drive/MyDrive/soumya/complete_balanced_data.csv\"\n",
        "    results = main(input_file_path)\n",
        "    print(f\"Final results: {results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzCJP7BG4CX2"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5E0XlIDNDcKq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRFlUaaD7ACt",
        "outputId": "e36942e9-4663-461f-97f2-25599da02df7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Text: ['As wildfires rage across California, floods displace thousands in the Midwest, and heatwaves scorch cities from Texas to New York, the evidence is undeniable: the climate crisis is no longer a distant threat—it’s here. And yet, as communities suffer and ecosystems collapse, fossil fuel corporations continue to post record-breaking profits, protected by conservative politicians and a global system rigged in their favor.\\nIn 2024 alone, the five largest oil companies reported over $200 billion in profits. Instead of investing in renewable energy or helping vulnerable communities transition to a green economy, these corporations funneled billions into stock buybacks and executive bonuses. Their message is clear: profits come before people, and the planet can burn so long as the shareholders stay rich.\\nEven more alarming is the political shielding they receive from right-wing lawmakers, many of whom deny climate science altogether. Republican leaders in Congress have repeatedly blocked climate legislation, gutted the Environmental Protection Agency’s regulatory powers, and prioritized drilling permits over clean air and water.\\nMeanwhile, climate activists—many of them youth, Indigenous leaders, and marginalized communities—continue to face police repression, surveillance, and criminalization. Peaceful protesters at pipeline sites are arrested, while oil spills and environmental destruction go unpunished.\\nWe need a Green New Deal-level transformation: bold investments in wind, solar, and green infrastructure; the creation of millions of unionized green jobs; and climate reparations for communities hit hardest by pollution and environmental racism.\\nThe time for delay is over. The time to act is now.']\n",
            "Predicted Bias: left \n",
            " confidence score:(0.9995)\n",
            "\n",
            "Text: [\"The United States thrives when government steps back and lets free enterprise lead. In recent years, however, progressive lawmakers have increasingly pushed for regulation, redistribution, and intervention that stifles innovation and discourages hard work.\\nFrom overreaching environmental mandates to government-controlled healthcare proposals, the left continues to champion policies that prioritize bureaucracy over results. These moves are not only anti-business—they’re anti-American.\\nAmerica's economic engine runs best when the private sector is free to create, compete, and grow. Small business owners across the country are already struggling with inflation and labor shortages—problems worsened by excessive government interference and rising taxes.\\nWe must return to policies that reward productivity, protect property rights, and uphold free-market values. Deregulation, tax reform, and energy independence will not only restore our economy—they’ll renew our national spirit.\\n\"]\n",
            "Predicted Bias: right \n",
            " confidence score:(0.9987)\n",
            "\n",
            "Text: ['As artificial intelligence tools become increasingly integrated into everyday life—from health diagnostics to criminal justice systems—Democratic and Republican lawmakers alike are recognizing the need for clear regulatory frameworks.\\nA bipartisan group in Congress recently introduced the American AI Responsibility Act, aiming to address transparency, data privacy, and algorithmic bias. While the bill doesn’t go as far as some activists demand, it marks an important step toward balancing innovation with accountability.\\nTech CEOs have expressed cautious support, stating that some regulation is needed to maintain public trust, but they warn against overregulation that could drive development offshore.\\nExperts agree: regulation must be careful, measured, and informed by the science—not by political theater. While divisions remain, the shared concern over AI’s risks may offer a rare opportunity for consensus in Washington.\\n']\n",
            "Predicted Bias: center \n",
            " confidence score:(0.9131)\n",
            "\n",
            "Text: ['In yet another blow to working-class Americans, Senate Republicans have blocked legislation that would raise the federal minimum wage to $17 per hour by 2027. With wages stagnant and inflation hitting food, rent, and transportation costs, the move is being widely condemned by labor leaders and economists.\\nThe current $7.25 minimum wage has not been raised since 2009, despite historic gains in productivity and corporate profits. Over 60% of Americans support a raise, but Republican lawmakers claim it would “hurt small businesses”—an argument that many economists say is overblown.\\nIn reality, the refusal to raise wages preserves exploitative systems where billion-dollar corporations rely on underpaid workers while CEO salaries skyrocket.\\nThis is not just about economics—it’s about dignity. Every American who works full-time should be able to afford basic necessities. Congress’s failure to act is a moral failure, and it’s up to voters to hold them accountable.']\n",
            "Predicted Bias: left \n",
            " confidence score:(0.9995)\n",
            "\n",
            "Text: ['The southern border has long been a flashpoint in American politics, but recent data shows that tougher enforcement and advanced surveillance technology are yielding results. Illegal crossings dropped 30% in the first quarter of 2025 compared to the previous year, according to Homeland Security reports.\\nUnder the new measures, authorities have deployed AI-powered drones, reinforced border fencing, and accelerated asylum screening procedures. Critics on the left say the policies are “inhumane,” but officials argue they are necessary to protect national sovereignty and public safety.\\nDrug seizures have also increased, particularly fentanyl shipments originating from cartels that exploit weak border points. Law enforcement agencies say the new tools and funding are making a significant impact.\\nThe Biden administration was slow to act early in its term, but this policy shift marks a necessary correction. The right to immigrate must be balanced with the rule of law—and American citizens deserve to feel safe and secure in their own country.\\n']\n",
            "Predicted Bias: center \n",
            " confidence score:(0.5516)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_path = \"/content/drive/MyDrive/soumya/results\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path,local_files_only=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "test_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
        "\n",
        "samples = [\n",
        "[\"\"\"As wildfires rage across California, floods displace thousands in the Midwest, and heatwaves scorch cities from Texas to New York, the evidence is undeniable: the climate crisis is no longer a distant threat—it’s here. And yet, as communities suffer and ecosystems collapse, fossil fuel corporations continue to post record-breaking profits, protected by conservative politicians and a global system rigged in their favor.\n",
        "In 2024 alone, the five largest oil companies reported over $200 billion in profits. Instead of investing in renewable energy or helping vulnerable communities transition to a green economy, these corporations funneled billions into stock buybacks and executive bonuses. Their message is clear: profits come before people, and the planet can burn so long as the shareholders stay rich.\n",
        "Even more alarming is the political shielding they receive from right-wing lawmakers, many of whom deny climate science altogether. Republican leaders in Congress have repeatedly blocked climate legislation, gutted the Environmental Protection Agency’s regulatory powers, and prioritized drilling permits over clean air and water.\n",
        "Meanwhile, climate activists—many of them youth, Indigenous leaders, and marginalized communities—continue to face police repression, surveillance, and criminalization. Peaceful protesters at pipeline sites are arrested, while oil spills and environmental destruction go unpunished.\n",
        "We need a Green New Deal-level transformation: bold investments in wind, solar, and green infrastructure; the creation of millions of unionized green jobs; and climate reparations for communities hit hardest by pollution and environmental racism.\n",
        "The time for delay is over. The time to act is now.\"\"\"\n",
        "],\n",
        "[\"\"\"The United States thrives when government steps back and lets free enterprise lead. In recent years, however, progressive lawmakers have increasingly pushed for regulation, redistribution, and intervention that stifles innovation and discourages hard work.\n",
        "From overreaching environmental mandates to government-controlled healthcare proposals, the left continues to champion policies that prioritize bureaucracy over results. These moves are not only anti-business—they’re anti-American.\n",
        "America's economic engine runs best when the private sector is free to create, compete, and grow. Small business owners across the country are already struggling with inflation and labor shortages—problems worsened by excessive government interference and rising taxes.\n",
        "We must return to policies that reward productivity, protect property rights, and uphold free-market values. Deregulation, tax reform, and energy independence will not only restore our economy—they’ll renew our national spirit.\n",
        "\"\"\"],\n",
        "[\"\"\"As artificial intelligence tools become increasingly integrated into everyday life—from health diagnostics to criminal justice systems—Democratic and Republican lawmakers alike are recognizing the need for clear regulatory frameworks.\n",
        "A bipartisan group in Congress recently introduced the American AI Responsibility Act, aiming to address transparency, data privacy, and algorithmic bias. While the bill doesn’t go as far as some activists demand, it marks an important step toward balancing innovation with accountability.\n",
        "Tech CEOs have expressed cautious support, stating that some regulation is needed to maintain public trust, but they warn against overregulation that could drive development offshore.\n",
        "Experts agree: regulation must be careful, measured, and informed by the science—not by political theater. While divisions remain, the shared concern over AI’s risks may offer a rare opportunity for consensus in Washington.\n",
        "\"\"\"],\n",
        "[\"\"\"In yet another blow to working-class Americans, Senate Republicans have blocked legislation that would raise the federal minimum wage to $17 per hour by 2027. With wages stagnant and inflation hitting food, rent, and transportation costs, the move is being widely condemned by labor leaders and economists.\n",
        "The current $7.25 minimum wage has not been raised since 2009, despite historic gains in productivity and corporate profits. Over 60% of Americans support a raise, but Republican lawmakers claim it would “hurt small businesses”—an argument that many economists say is overblown.\n",
        "In reality, the refusal to raise wages preserves exploitative systems where billion-dollar corporations rely on underpaid workers while CEO salaries skyrocket.\n",
        "This is not just about economics—it’s about dignity. Every American who works full-time should be able to afford basic necessities. Congress’s failure to act is a moral failure, and it’s up to voters to hold them accountable.\"\"\"],\n",
        " [\"\"\"The southern border has long been a flashpoint in American politics, but recent data shows that tougher enforcement and advanced surveillance technology are yielding results. Illegal crossings dropped 30% in the first quarter of 2025 compared to the previous year, according to Homeland Security reports.\n",
        "Under the new measures, authorities have deployed AI-powered drones, reinforced border fencing, and accelerated asylum screening procedures. Critics on the left say the policies are “inhumane,” but officials argue they are necessary to protect national sovereignty and public safety.\n",
        "Drug seizures have also increased, particularly fentanyl shipments originating from cartels that exploit weak border points. Law enforcement agencies say the new tools and funding are making a significant impact.\n",
        "The Biden administration was slow to act early in its term, but this policy shift marks a necessary correction. The right to immigrate must be balanced with the rule of law—and American citizens deserve to feel safe and secure in their own country.\n",
        "\"\"\"]\n",
        "]\n",
        "\n",
        "for text in samples:\n",
        "    output = test_pipeline(text, truncation=True, max_length=512)\n",
        "    sorted_output = sorted(output[0], key=lambda x: x[\"score\"], reverse=True)\n",
        "    top_label = sorted_output[0]\n",
        "\n",
        "    label_map = {\n",
        "    0: \"left\", 1: \"center\", 2: \"right\"}\n",
        "    # Extract the numeric part of the label like 'LABEL_1' -> 1\n",
        "    label_index = int(top_label['label'].split('_')[-1])\n",
        "    readable_label = label_map[label_index]\n",
        "\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"Predicted Bias: {readable_label} \\n confidence score:({top_label['score']:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report, confusion_matrix\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from functools import lru_cache\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "MODEL_NAME = \"launch/politics\"  # POLITICS model\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/soumya/results\"\n",
        "LOGGING_DIR = \"/content/drive/MyDrive/soumya/logs\"\n",
        "RESULTS_PATH = \"/content/drive/MyDrive/soumya/results/predictions.csv\"\n",
        "CACHE_DIR = \"/content/drive/MyDrive/soumya/results/cache\"\n",
        "DATASET_CACHE_DIR = \"/content/drive/MyDrive/soumya/result/dataset_cache\"\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "# Ensure directories exist\n",
        "for directory in [OUTPUT_DIR, LOGGING_DIR, CACHE_DIR, DATASET_CACHE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "# Optimize memory usage\n",
        "def optimize_memory():\n",
        "    config = {\n",
        "        \"batch_size\": 8,\n",
        "        \"eval_batch_size\": 16,\n",
        "        \"num_workers\": min(os.cpu_count() - 1, 4) if os.cpu_count() > 1 else 0,\n",
        "        \"gradient_accumulation_steps\": 2,\n",
        "        \"mixed_precision\": False\n",
        "    }\n",
        "    if torch.cuda.is_available():\n",
        "        logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        logger.info(f\"GPU Memory: {total_memory:.2f} GB\")\n",
        "        torch.cuda.empty_cache()\n",
        "        if total_memory > 10:\n",
        "            config[\"batch_size\"] = 16\n",
        "            config[\"eval_batch_size\"] = 32\n",
        "            config[\"gradient_accumulation_steps\"] = 1\n",
        "        elif total_memory < 4:\n",
        "            config[\"batch_size\"] = 4\n",
        "            config[\"eval_batch_size\"] = 8\n",
        "            config[\"gradient_accumulation_steps\"] = 4\n",
        "        config[\"mixed_precision\"] = True\n",
        "    return config\n",
        "\n",
        "memory_config = optimize_memory()\n",
        "\n",
        "# Text Processing Functions\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "@lru_cache(maxsize=1024)\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text) or text is None:\n",
        "        return \"\"\n",
        "    text = str(text).lower().strip()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    available_cols = [col for col in text_cols if col in df.columns]\n",
        "    if not available_cols:\n",
        "        logger.error(\"No valid text columns found\")\n",
        "        sys.exit(1)\n",
        "    processed_cols = {col: df[col].apply(preprocess_text) if col in df.columns else pd.Series([\"\"] * len(df)) for col in text_cols}\n",
        "    combined_series = processed_cols[text_cols[0]].copy()\n",
        "    for col in text_cols[1:]:\n",
        "        mask = processed_cols[col] != \"\"\n",
        "        combined_series[mask] = combined_series[mask] + \" \" + processed_cols[col][mask]\n",
        "    return combined_series\n",
        "\n",
        "def create_data_from_batch(batch_df, tokenizer, max_length=MAX_LENGTH):\n",
        "    texts = batch_df[\"combined_input\"].tolist()\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    labels = None\n",
        "    if \"label\" in batch_df:\n",
        "        labels = torch.tensor(batch_df[\"label\"].tolist())\n",
        "    return {\n",
        "        \"input_ids\": encodings[\"input_ids\"],\n",
        "        \"attention_mask\": encodings[\"attention_mask\"],\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "# Load and Process Data\n",
        "def load_data(file_path):\n",
        "    cache_file = os.path.join(DATASET_CACHE_DIR, f\"{os.path.basename(file_path)}.processed.pkl\")\n",
        "    if os.path.exists(cache_file):\n",
        "        logger.info(f\"Loading processed data from cache: {cache_file}\")\n",
        "        return pd.read_pickle(cache_file)\n",
        "    \n",
        "    logger.info(\"Loading and processing data\")\n",
        "    if not os.path.exists(file_path):\n",
        "        logger.error(f\"Input file not found: {file_path}\")\n",
        "        sys.exit(1)\n",
        "    \n",
        "    try:\n",
        "        if file_path.endswith('.xlsx'):\n",
        "            df = pd.read_excel(file_path, engine='openpyxl')\n",
        "        elif file_path.endswith('.csv'):\n",
        "            df = pd.read_csv(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading data: {e}\")\n",
        "        sys.exit(1)\n",
        "    \n",
        "    required_cols = [\"text\", \"type\"]\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        logger.error(f\"Missing required columns: {required_cols}\")\n",
        "        sys.exit(1)\n",
        "    \n",
        "    df = df[df[\"type\"].isin(LABEL_MAP.keys())]\n",
        "    logger.info(\"Class distribution:\")\n",
        "    logger.info(df[\"type\"].value_counts())\n",
        "    \n",
        "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
        "    df[\"combined_input\"] = combine_text(df, text_cols)\n",
        "    df[\"label\"] = df[\"type\"].map(LABEL_MAP)\n",
        "    \n",
        "    logger.info(f\"Sample data:\\n{df[['combined_input', 'type']].head(5).to_string()}\")\n",
        "    df.to_pickle(cache_file)\n",
        "    logger.info(f\"Processed data cached to: {cache_file}\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Dataset Class\n",
        "class PoliticalBiasDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=MAX_LENGTH):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.has_labels = \"label\" in df.columns\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = {\"combined_input\": self.df.iloc[idx][\"combined_input\"]}\n",
        "        if self.has_labels:\n",
        "            item[\"label\"] = self.df.iloc[idx][\"label\"]\n",
        "        return item\n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "        batch_df = pd.DataFrame(batch)\n",
        "        return create_data_from_batch(batch_df, self.tokenizer, self.max_length)\n",
        "\n",
        "# Metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    class_report = classification_report(labels, preds, target_names=LABEL_MAP.keys(), output_dict=True)\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=LABEL_MAP.keys(), yticklabels=LABEL_MAP.keys())\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    cm_path = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\n",
        "    plt.savefig(cm_path)\n",
        "    plt.close()\n",
        "    logger.info(f\"Confusion matrix saved to {cm_path}\")\n",
        "    \n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "    for cls in LABEL_MAP.keys():\n",
        "        metrics[f\"f1_{cls}\"] = class_report[cls]['f1-score']\n",
        "    \n",
        "    logger.info(f\"Classification Report:\\n{classification_report(labels, preds, target_names=LABEL_MAP.keys())}\")\n",
        "    return metrics\n",
        "\n",
        "# Custom Trainer with Class Weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "    \n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Main Pipeline\n",
        "def main(file_path):\n",
        "    logger.info(\"Starting main pipeline\")\n",
        "    \n",
        "    # Load and prepare data\n",
        "    df = load_data(file_path)\n",
        "    \n",
        "    # Train-Test Split\n",
        "    logger.info(\"Splitting data\")\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df[\"label\"], random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
        "    \n",
        "    logger.info(f\"Train set: {len(train_df)} samples\")\n",
        "    logger.info(f\"Validation set: {len(val_df)} samples\")\n",
        "    logger.info(f\"Test set: {len(test_df)} samples\")\n",
        "    \n",
        "    # Load Tokenizer and Model\n",
        "    logger.info(f\"Loading tokenizer and model: {MODEL_NAME}\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            num_labels=len(LABEL_MAP),\n",
        "            cache_dir=CACHE_DIR,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "        logger.info(f\"Successfully loaded model: {MODEL_NAME}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load model {MODEL_NAME}: {e}\")\n",
        "        raise\n",
        "    \n",
        "    model.to(device)\n",
        "    \n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(train_df[\"label\"]), y=train_df[\"label\"])\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "    logger.info(f\"Class weights: {class_weights.tolist()}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = PoliticalBiasDataset(train_df, tokenizer)\n",
        "    val_dataset = PoliticalBiasDataset(val_df, tokenizer)\n",
        "    test_dataset = PoliticalBiasDataset(test_df, tokenizer)\n",
        "    \n",
        "    # Training Arguments\n",
        "    logger.info(\"Setting up training arguments\")\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        logging_dir=LOGGING_DIR,\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=100,\n",
        "        per_device_train_batch_size=memory_config[\"batch_size\"],\n",
        "        per_device_eval_batch_size=memory_config[\"eval_batch_size\"],\n",
        "        gradient_accumulation_steps=memory_config[\"gradient_accumulation_steps\"],\n",
        "        num_train_epochs=10,\n",
        "        learning_rate=2e-5,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        save_total_limit=2,\n",
        "        report_to=\"none\",\n",
        "        fp16=memory_config[\"mixed_precision\"],\n",
        "        dataloader_num_workers=memory_config[\"num_workers\"],\n",
        "        remove_unused_columns=False,\n",
        "        disable_tqdm=False,\n",
        "        gradient_checkpointing=True,\n",
        "        lr_scheduler_type=\"linear\"\n",
        "    )\n",
        "    \n",
        "    # Initialize Trainer\n",
        "    logger.info(\"Initializing Trainer\")\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=train_dataset.collate_fn,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "        class_weights=class_weights\n",
        "    )\n",
        "    \n",
        "    # Train\n",
        "    logger.info(\"Starting training\")\n",
        "    trainer.train()\n",
        "    trainer.save_metrics(\"all\", trainer.metrics)\n",
        "    logger.info(f\"Training metrics saved to {LOGGING_DIR}\")\n",
        "    \n",
        "    # Save model and tokenizer\n",
        "    logger.info(\"Saving model and tokenizer\")\n",
        "    model.save_pretrained(OUTPUT_DIR)\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "    logger.info(f\"Model and tokenizer saved to {OUTPUT_DIR}\")\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    logger.info(\"Evaluating on test set\")\n",
        "    test_results = trainer.evaluate(test_dataset)\n",
        "    logger.info(f\"Test results: {test_results}\")\n",
        "    for metric, value in test_results.items():\n",
        "        logger.info(f\"{metric}: {value:.4f}\")\n",
        "    \n",
        "    # Make predictions\n",
        "    logger.info(\"Making predictions on all data\")\n",
        "    full_dataset = PoliticalBiasDataset(df[[\"combined_input\"]], tokenizer)\n",
        "    prediction_dataloader = DataLoader(\n",
        "        full_dataset,\n",
        "        batch_size=memory_config[\"eval_batch_size\"],\n",
        "        collate_fn=full_dataset.collate_fn,\n",
        "        num_workers=memory_config[\"num_workers\"],\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    all_predictions = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(prediction_dataloader, desc=\"Predicting\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            all_predictions.extend(batch_preds)\n",
        "    \n",
        "    # Save predictions\n",
        "    df[\"predicted_bias_category\"] = [REVERSE_LABEL_MAP[i] for i in all_predictions]\n",
        "    df.to_csv(RESULTS_PATH, index=False)\n",
        "    logger.info(f\"Predictions saved to {RESULTS_PATH}\")\n",
        "    \n",
        "    # Save misclassified examples\n",
        "    misclassified = df[df[\"label\"] != df[\"predicted_bias_category\"].map(LABEL_MAP)]\n",
        "    misclassified_path = os.path.join(OUTPUT_DIR, \"misclassified_examples.csv\")\n",
        "    misclassified.to_csv(misclassified_path, index=False)\n",
        "    logger.info(f\"Misclassified examples saved to {misclassified_path}\")\n",
        "    \n",
        "    # Clean up GPU memory\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    return test_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file_path = \"/content/drive/MyDrive/soumya/complete_balanced_data.csv\"\n",
        "    results = main(input_file_path)\n",
        "    print(f\"Final results: {results}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
