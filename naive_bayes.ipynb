{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score,confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datasets import Dataset\n",
    "from joblib import load,dump\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:05:43,864 - INFO - Starting chunked Naive Bayes pipeline\n",
      "2025-05-07 15:05:43,865 - INFO - Loading and preprocessing data in chunks\n",
      "2025-05-07 15:05:46,801 - INFO - Splitting data into train and eval sets\n",
      "2025-05-07 15:05:46,865 - INFO - Preparing data\n",
      "2025-05-07 15:05:46,866 - INFO - Training model\n",
      "2025-05-07 15:05:46,867 - INFO - Setting up Naive Bayes pipeline\n",
      "2025-05-07 15:05:46,868 - INFO - Training Naive Bayes model\n",
      "2025-05-07 15:05:53,714 - INFO - Computing metrics\n",
      "2025-05-07 15:05:53,723 - INFO - Evaluation metrics: {'accuracy': 0.9028097062579821, 'f1': 0.9027908482128976, 'precision': 0.9027999218746129, 'recall': 0.9028097062579821}\n",
      "2025-05-07 15:05:53,724 - INFO - Saving model\n",
      "2025-05-07 15:05:53,888 - INFO - Making predictions\n",
      "2025-05-07 15:05:53,889 - INFO - Predicting batch 1/79\n",
      "2025-05-07 15:05:53,985 - INFO - Predicting batch 2/79\n",
      "2025-05-07 15:05:54,076 - INFO - Predicting batch 3/79\n",
      "2025-05-07 15:05:54,171 - INFO - Predicting batch 4/79\n",
      "2025-05-07 15:05:54,256 - INFO - Predicting batch 5/79\n",
      "2025-05-07 15:05:54,346 - INFO - Predicting batch 6/79\n",
      "2025-05-07 15:05:54,443 - INFO - Predicting batch 7/79\n",
      "2025-05-07 15:05:54,516 - INFO - Predicting batch 8/79\n",
      "2025-05-07 15:05:54,614 - INFO - Predicting batch 9/79\n",
      "2025-05-07 15:05:54,712 - INFO - Predicting batch 10/79\n",
      "2025-05-07 15:05:54,792 - INFO - Predicting batch 11/79\n",
      "2025-05-07 15:05:54,881 - INFO - Predicting batch 12/79\n",
      "2025-05-07 15:05:54,973 - INFO - Predicting batch 13/79\n",
      "2025-05-07 15:05:55,069 - INFO - Predicting batch 14/79\n",
      "2025-05-07 15:05:55,165 - INFO - Predicting batch 15/79\n",
      "2025-05-07 15:05:55,258 - INFO - Predicting batch 16/79\n",
      "2025-05-07 15:05:55,352 - INFO - Predicting batch 17/79\n",
      "2025-05-07 15:05:55,441 - INFO - Predicting batch 18/79\n",
      "2025-05-07 15:05:55,541 - INFO - Predicting batch 19/79\n",
      "2025-05-07 15:05:55,637 - INFO - Predicting batch 20/79\n",
      "2025-05-07 15:05:55,736 - INFO - Predicting batch 21/79\n",
      "2025-05-07 15:05:55,831 - INFO - Predicting batch 22/79\n",
      "2025-05-07 15:05:55,922 - INFO - Predicting batch 23/79\n",
      "2025-05-07 15:05:56,007 - INFO - Predicting batch 24/79\n",
      "2025-05-07 15:05:56,092 - INFO - Predicting batch 25/79\n",
      "2025-05-07 15:05:56,181 - INFO - Predicting batch 26/79\n",
      "2025-05-07 15:05:56,267 - INFO - Predicting batch 27/79\n",
      "2025-05-07 15:05:56,352 - INFO - Predicting batch 28/79\n",
      "2025-05-07 15:05:56,491 - INFO - Predicting batch 29/79\n",
      "2025-05-07 15:05:56,592 - INFO - Predicting batch 30/79\n",
      "2025-05-07 15:05:56,680 - INFO - Predicting batch 31/79\n",
      "2025-05-07 15:05:56,770 - INFO - Predicting batch 32/79\n",
      "2025-05-07 15:05:56,863 - INFO - Predicting batch 33/79\n",
      "2025-05-07 15:05:56,957 - INFO - Predicting batch 34/79\n",
      "2025-05-07 15:05:57,043 - INFO - Predicting batch 35/79\n",
      "2025-05-07 15:05:57,123 - INFO - Predicting batch 36/79\n",
      "2025-05-07 15:05:57,212 - INFO - Predicting batch 37/79\n",
      "2025-05-07 15:05:57,300 - INFO - Predicting batch 38/79\n",
      "2025-05-07 15:05:57,384 - INFO - Predicting batch 39/79\n",
      "2025-05-07 15:05:57,482 - INFO - Predicting batch 40/79\n",
      "2025-05-07 15:05:57,563 - INFO - Predicting batch 41/79\n",
      "2025-05-07 15:05:57,651 - INFO - Predicting batch 42/79\n",
      "2025-05-07 15:05:57,738 - INFO - Predicting batch 43/79\n",
      "2025-05-07 15:05:57,825 - INFO - Predicting batch 44/79\n",
      "2025-05-07 15:05:57,902 - INFO - Predicting batch 45/79\n",
      "2025-05-07 15:05:57,981 - INFO - Predicting batch 46/79\n",
      "2025-05-07 15:05:58,068 - INFO - Predicting batch 47/79\n",
      "2025-05-07 15:05:58,152 - INFO - Predicting batch 48/79\n",
      "2025-05-07 15:05:58,230 - INFO - Predicting batch 49/79\n",
      "2025-05-07 15:05:58,325 - INFO - Predicting batch 50/79\n",
      "2025-05-07 15:05:58,418 - INFO - Predicting batch 51/79\n",
      "2025-05-07 15:05:58,508 - INFO - Predicting batch 52/79\n",
      "2025-05-07 15:05:58,602 - INFO - Predicting batch 53/79\n",
      "2025-05-07 15:05:58,710 - INFO - Predicting batch 54/79\n",
      "2025-05-07 15:05:58,800 - INFO - Predicting batch 55/79\n",
      "2025-05-07 15:05:58,889 - INFO - Predicting batch 56/79\n",
      "2025-05-07 15:05:58,983 - INFO - Predicting batch 57/79\n",
      "2025-05-07 15:05:59,069 - INFO - Predicting batch 58/79\n",
      "2025-05-07 15:05:59,155 - INFO - Predicting batch 59/79\n",
      "2025-05-07 15:05:59,256 - INFO - Predicting batch 60/79\n",
      "2025-05-07 15:05:59,343 - INFO - Predicting batch 61/79\n",
      "2025-05-07 15:05:59,439 - INFO - Predicting batch 62/79\n",
      "2025-05-07 15:05:59,527 - INFO - Predicting batch 63/79\n",
      "2025-05-07 15:05:59,615 - INFO - Predicting batch 64/79\n",
      "2025-05-07 15:05:59,707 - INFO - Predicting batch 65/79\n",
      "2025-05-07 15:05:59,804 - INFO - Predicting batch 66/79\n",
      "2025-05-07 15:05:59,905 - INFO - Predicting batch 67/79\n",
      "2025-05-07 15:05:59,995 - INFO - Predicting batch 68/79\n",
      "2025-05-07 15:06:00,078 - INFO - Predicting batch 69/79\n",
      "2025-05-07 15:06:00,158 - INFO - Predicting batch 70/79\n",
      "2025-05-07 15:06:00,258 - INFO - Predicting batch 71/79\n",
      "2025-05-07 15:06:00,346 - INFO - Predicting batch 72/79\n",
      "2025-05-07 15:06:00,432 - INFO - Predicting batch 73/79\n",
      "2025-05-07 15:06:00,519 - INFO - Predicting batch 74/79\n",
      "2025-05-07 15:06:00,607 - INFO - Predicting batch 75/79\n",
      "2025-05-07 15:06:00,696 - INFO - Predicting batch 76/79\n",
      "2025-05-07 15:06:00,783 - INFO - Predicting batch 77/79\n",
      "2025-05-07 15:06:00,872 - INFO - Predicting batch 78/79\n",
      "2025-05-07 15:06:00,964 - INFO - Predicting batch 79/79\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 140\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    139\u001b[0m     input_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete_balanced_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 140\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 133\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    130\u001b[0m full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_bias_category\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [REVERSE_LABEL_MAP[p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m predictions]\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# 7. Save results\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[43mfull_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRESULTS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRESULTS_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m full_df\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/results'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
    "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "OUTPUT_DIR = \"./results\"\n",
    "LOGGING_DIR = \"./logs\"\n",
    "RESULTS_PATH = \"./results/predictions.csv\"\n",
    "SAVE_PATH = OUTPUT_DIR\n",
    "CHUNK_SIZE = 1000  # Adjust based on your memory capacity\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(LOGGING_DIR, exist_ok=True)\n",
    "\n",
    "# Text Processing Functions\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by converting to lowercase and handling non-string inputs.\"\"\"\n",
    "    if isinstance(text, list):\n",
    "        return ' '.join(str(t).lower() for t in text if isinstance(t, str))\n",
    "    return str(text).lower()\n",
    "\n",
    "def combine_text(df, text_cols):\n",
    "    \"\"\"Combine text columns into a single 'combined_input' column.\"\"\"\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
    "    df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "    return df\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute evaluation metrics.\"\"\"\n",
    "    logger.info(\"Computing metrics\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Chunked Data Processing\n",
    "def process_chunks(file_path, process_fn):\n",
    "    \"\"\"Process data in chunks and collect results.\"\"\"\n",
    "    results = []\n",
    "    for chunk in pd.read_csv(file_path,chunksize=CHUNK_SIZE):\n",
    "        processed = process_fn(chunk)\n",
    "        results.append(processed)\n",
    "    return pd.concat(results)\n",
    "\n",
    "def preprocess_chunk(chunk):\n",
    "    \"\"\"Preprocess a single chunk of data.\"\"\"\n",
    "    chunk = chunk[chunk[\"type\"].isin(LABEL_MAP.keys())]\n",
    "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
    "    chunk_processed = combine_text(chunk, text_cols)\n",
    "    chunk_processed[\"label\"] = chunk_processed[\"type\"].map(LABEL_MAP)\n",
    "    return chunk_processed\n",
    "\n",
    "# Main Training Function\n",
    "def train_model(X_train, y_train, X_eval, y_eval):\n",
    "    \"\"\"Train the Naive Bayes model with given datasets.\"\"\"\n",
    "    logger.info(\"Setting up Naive Bayes pipeline\")\n",
    "    \n",
    "    # Create pipeline with TF-IDF vectorizer and Naive Bayes\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "        ('nb', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    logger.info(\"Training Naive Bayes model\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = pipeline.predict(X_eval)\n",
    "    metrics = compute_metrics(y_eval, y_pred)\n",
    "    logger.info(f\"Evaluation metrics: {metrics}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Prediction Function\n",
    "def predict_in_chunks(model, full_df, batch_size=1000):\n",
    "    \"\"\"Make predictions in batches to handle large datasets.\"\"\"\n",
    "    all_preds = []\n",
    "    for i in range(0, len(full_df), batch_size):\n",
    "        logger.info(f\"Predicting batch {i//batch_size + 1}/{(len(full_df)//batch_size)+1}\")\n",
    "        chunk = full_df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Predict\n",
    "        preds = model.predict(chunk[\"combined_input\"])\n",
    "        all_preds.extend(preds)\n",
    "    \n",
    "    return all_preds\n",
    "\n",
    "# Main Pipeline\n",
    "def main(file_path):\n",
    "    logger.info(\"Starting chunked Naive Bayes pipeline\")\n",
    "    \n",
    "    # 1. Load and preprocess data in chunks\n",
    "    logger.info(\"Loading and preprocessing data in chunks\")\n",
    "    full_df = process_chunks(file_path, preprocess_chunk)\n",
    "    \n",
    "    # 2. Train-test split\n",
    "    logger.info(\"Splitting data into train and eval sets\")\n",
    "    train_df, eval_df = train_test_split(\n",
    "        full_df, \n",
    "        test_size=0.2, \n",
    "        stratify=full_df[\"label\"], \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 3. Prepare data\n",
    "    logger.info(\"Preparing data\")\n",
    "    X_train = train_df[\"combined_input\"]\n",
    "    y_train = train_df[\"label\"]\n",
    "    X_eval = eval_df[\"combined_input\"]\n",
    "    y_eval = eval_df[\"label\"]\n",
    "    \n",
    "    # 4. Train model\n",
    "    logger.info(\"Training model\")\n",
    "    model = train_model(X_train, y_train, X_eval, y_eval)\n",
    "    \n",
    "    # 5. Save model (using joblib for scikit-learn models)\n",
    "    logger.info(\"Saving model\")\n",
    "    from joblib import dump\n",
    "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "    dump(model, os.path.join(SAVE_PATH, \"naive_bayes_model.joblib\"))\n",
    "    \n",
    "    # 6. Make predictions\n",
    "    logger.info(\"Making predictions\")\n",
    "    predictions = predict_in_chunks(model, full_df)\n",
    "    full_df[\"predicted_bias_category\"] = [REVERSE_LABEL_MAP[p] for p in predictions]\n",
    "    \n",
    "    # 7. Save results\n",
    "    full_df.to_csv(RESULTS_PATH, index=False)\n",
    "    logger.info(f\"Results saved to {RESULTS_PATH}\")\n",
    "    \n",
    "    return full_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file_path = \"complete_balanced_data.csv\"\n",
    "    results_df = main(input_file_path)\n",
    "    logger.info(\"completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:16:42,230 - INFO - Starting sample prediction pipeline with confidence scores\n",
      "2025-05-07 15:16:42,232 - INFO - Preprocessing samples\n",
      "2025-05-07 15:16:42,233 - INFO - Loading trained Naive Bayes model\n",
      "2025-05-07 15:16:42,304 - INFO - Making predictions on samples\n",
      "2025-05-07 15:16:42,315 - INFO - Sample predictions saved to ./results/sample_predictions.csv\n",
      "2025-05-07 15:16:42,316 - INFO - Sample 1:\n",
      "2025-05-07 15:16:42,316 - INFO - Predicted Bias: left \n",
      " confidence score: (0.8114)\n",
      "2025-05-07 15:16:42,318 - INFO - Sample text (truncated): as wildfires rage across california, floods displace thousands in the midwest, and heatwaves scorch ...\n",
      "2025-05-07 15:16:42,318 - INFO - Sample 2:\n",
      "2025-05-07 15:16:42,319 - INFO - Predicted Bias: right \n",
      " confidence score: (0.6545)\n",
      "2025-05-07 15:16:42,320 - INFO - Sample text (truncated): the united states thrives when government steps back and lets free enterprise lead. in recent years,...\n",
      "2025-05-07 15:16:42,320 - INFO - Sample 3:\n",
      "2025-05-07 15:16:42,321 - INFO - Predicted Bias: center \n",
      " confidence score: (0.4073)\n",
      "2025-05-07 15:16:42,321 - INFO - Sample text (truncated): as artificial intelligence tools become increasingly integrated into everyday life—from health diagn...\n",
      "2025-05-07 15:16:42,322 - INFO - Sample 4:\n",
      "2025-05-07 15:16:42,323 - INFO - Predicted Bias: left \n",
      " confidence score: (0.6922)\n",
      "2025-05-07 15:16:42,324 - INFO - Sample text (truncated): in yet another blow to working-class americans, senate republicans have blocked legislation that wou...\n",
      "2025-05-07 15:16:42,324 - INFO - Sample 5:\n",
      "2025-05-07 15:16:42,326 - INFO - Predicted Bias: center \n",
      " confidence score: (0.5987)\n",
      "2025-05-07 15:16:42,326 - INFO - Sample text (truncated): the southern border has long been a flashpoint in american politics, but recent data shows that toug...\n",
      "2025-05-07 15:16:42,327 - INFO - Sample prediction completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
    "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "MODEL_PATH = \"./results/naive_bayes_model.joblib\"\n",
    "OUTPUT_PATH = \"./results/sample_predictions.csv\"\n",
    "\n",
    "# Text Processing Function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by converting to lowercase and handling non-string inputs.\"\"\"\n",
    "    if isinstance(text, list):\n",
    "        return ' '.join(str(t).lower() for t in text if isinstance(t, str))\n",
    "    return str(text).lower()\n",
    "\n",
    "# Main Testing Function\n",
    "def test_samples(samples):\n",
    "    logger.info(\"Starting sample prediction pipeline with confidence scores\")\n",
    "    \n",
    "    # 1. Prepare samples as DataFrame\n",
    "    logger.info(\"Preprocessing samples\")\n",
    "    sample_df = pd.DataFrame({\n",
    "        \"combined_input\": [preprocess_text(sample[0]) for sample in samples]\n",
    "    })\n",
    "    \n",
    "    # 2. Load the trained model\n",
    "    logger.info(\"Loading trained Naive Bayes model\")\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        logger.error(f\"Model file not found at {MODEL_PATH}\")\n",
    "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}\")\n",
    "    \n",
    "    model = load(MODEL_PATH)\n",
    "    \n",
    "    # 3. Make predictions and get confidence scores\n",
    "    logger.info(\"Making predictions on samples\")\n",
    "    predictions = model.predict(sample_df[\"combined_input\"])\n",
    "    probabilities = model.predict_proba(sample_df[\"combined_input\"])\n",
    "    \n",
    "    # Extract confidence scores for predicted classes\n",
    "    confidence_scores = [prob[pred] for prob, pred in zip(probabilities, predictions)]\n",
    "    \n",
    "    # Add predictions and confidence scores to DataFrame\n",
    "    sample_df[\"predicted_bias_category\"] = [REVERSE_LABEL_MAP[p] for p in predictions]\n",
    "    sample_df[\"confidence_score\"] = confidence_scores\n",
    "    \n",
    "    # 4. Save results\n",
    "    sample_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    logger.info(f\"Sample predictions saved to {OUTPUT_PATH}\")\n",
    "    \n",
    "    # 5. Log predictions with confidence scores\n",
    "    for i, (text, pred, score) in enumerate(zip(sample_df[\"combined_input\"], sample_df[\"predicted_bias_category\"], sample_df[\"confidence_score\"])):\n",
    "        logger.info(f\"Sample {i+1}:\")\n",
    "        logger.info(f\"Predicted Bias: {pred} \\n confidence score: ({score:.4f})\")\n",
    "        logger.info(f\"Sample text (truncated): {text[:100]}...\")\n",
    "    \n",
    "    return sample_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provided samples\n",
    "    samples = [\n",
    "        [\"\"\"As wildfires rage across California, floods displace thousands in the Midwest, and heatwaves scorch cities from Texas to New York, the evidence is undeniable: the climate crisis is no longer a distant threat—it’s here. And yet, as communities suffer and ecosystems collapse, fossil fuel corporations continue to post record-breaking profits, protected by conservative politicians and a global system rigged in their favor.\n",
    "        In 2024 alone, the five largest oil companies reported over $200 billion in profits. Instead of investing in renewable energy or helping vulnerable communities transition to a green economy, these corporations funneled billions into stock buybacks and executive bonuses. Their message is clear: profits come before people, and the planet can burn so long as the shareholders stay rich.\n",
    "        Even more alarming is the political shielding they receive from right-wing lawmakers, many of whom deny climate science altogether. Republican leaders in Congress have repeatedly blocked climate legislation, gutted the Environmental Protection Agency’s regulatory powers, and prioritized drilling permits over clean air and water.\n",
    "        Meanwhile, climate activists—many of them youth, Indigenous leaders, and marginalized communities—continue to face police repression, surveillance, and criminalization. Peaceful protesters at pipeline sites are arrested, while oil spills and environmental destruction go unpunished.\n",
    "        We need a Green New Deal-level transformation: bold investments in wind, solar, and green infrastructure; the creation of millions of unionized green jobs; and climate reparations for communities hit hardest by pollution and environmental racism.\n",
    "        The time for delay is over. The time to act is now.\"\"\"],\n",
    "        [\"\"\"The United States thrives when government steps back and lets free enterprise lead. In recent years, however, progressive lawmakers have increasingly pushed for regulation, redistribution, and intervention that stifles innovation and discourages hard work.\n",
    "        From overreaching environmental mandates to government-controlled healthcare proposals, the left continues to champion policies that prioritize bureaucracy over results. These moves are not only anti-business—they’re anti-American.\n",
    "        America's economic engine runs best when the private sector is free to create, compete, and grow. Small business owners across the country are already struggling with inflation and labor shortages—problems worsened by excessive government interference and rising taxes.\n",
    "        We must return to policies that reward productivity, protect property rights, and uphold free-market values. Deregulation, tax reform, and energy independence will not only restore our economy—they’ll renew our national spirit.\"\"\"],\n",
    "        [\"\"\"As artificial intelligence tools become increasingly integrated into everyday life—from health diagnostics to criminal justice systems—Democratic and Republican lawmakers alike are recognizing the need for clear regulatory frameworks.\n",
    "        A bipartisan group in Congress recently introduced the American AI Responsibility Act, aiming to address transparency, data privacy, and algorithmic bias. While the bill doesn’t go as far as some activists demand, it marks an important step toward balancing innovation with accountability.\n",
    "        Tech CEOs have expressed cautious support, stating that some regulation is needed to maintain public trust, but they warn against overregulation that could drive development offshore.\n",
    "        Experts agree: regulation must be careful, measured, and informed by the science—not by political theater. While divisions remain, the shared concern over AI’s risks may offer a rare opportunity for consensus in Washington.\"\"\"],\n",
    "        [\"\"\"In yet another blow to working-class Americans, Senate Republicans have blocked legislation that would raise the federal minimum wage to $17 per hour by 2027. With wages stagnant and inflation hitting food, rent, and transportation costs, the move is being widely condemned by labor leaders and economists.\n",
    "        The current $7.25 minimum wage has not been raised since 2009, despite historic gains in productivity and corporate profits. Over 60% of Americans support a raise, but Republican lawmakers claim it would “hurt small businesses”—an argument that many economists say is overblown.\n",
    "        In reality, the refusal to raise wages preserves exploitative systems where billion-dollar corporations rely on underpaid workers while CEO salaries skyrocket.\n",
    "        This is not just about economics—it’s about dignity. Every American who works full-time should be able to afford basic necessities. Congress’s failure to act is a moral failure, and it’s up to voters to hold them accountable.\"\"\"],\n",
    "        [\"\"\"The southern border has long been a flashpoint in American politics, but recent data shows that tougher enforcement and advanced surveillance technology are yielding results. Illegal crossings dropped 30% in the first quarter of 2025 compared to the previous year, according to Homeland Security reports.\n",
    "        Under the new measures, authorities have deployed AI-powered drones, reinforced border fencing, and accelerated asylum screening procedures. Critics on the left say the policies are “inhumane,” but officials argue they are necessary to protect national sovereignty and public safety.\n",
    "        Drug seizures have also increased, particularly fentanyl shipments originating from cartels that exploit weak border points. Law enforcement agencies say the new tools and funding are making a significant impact.\n",
    "        The Biden administration was slow to act early in its term, but this policy shift marks a necessary correction. The right to immigrate must be balanced with the rule of law—and American citizens deserve to feel safe and secure in their own country.\"\"\"]\n",
    "    ]\n",
    "    \n",
    "    # Run the prediction\n",
    "    results_df = test_samples(samples)\n",
    "    logger.info(\"Sample prediction completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 15:37:47,186 - INFO - Starting Naive Bayes pipeline with count vectorizer\n",
      "2025-05-07 15:37:47,187 - INFO - Loading and preprocessing data in chunks\n",
      "2025-05-07 15:37:59,114 - INFO - Saved processed data to ./opt_results/processed_data.parquet\n",
      "2025-05-07 15:37:59,116 - INFO - Splitting data into train and eval sets\n",
      "2025-05-07 15:37:59,167 - INFO - Preparing data\n",
      "2025-05-07 15:37:59,169 - INFO - Setting up Naive Bayes pipeline\n",
      "2025-05-07 15:37:59,169 - INFO - Performing hyperparameter tuning\n",
      "2025-05-07 15:37:59,170 - INFO - Training with GridSearchCV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/pranavi/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2025-05-07 15:41:33,944 - INFO - Best parameters: {'clf__alpha': 0.1, 'vectorizer__max_features': 10000, 'vectorizer__ngram_range': (1, 2)}\n",
      "2025-05-07 15:41:33,945 - INFO - Evaluating model\n",
      "2025-05-07 15:41:38,611 - INFO - Computing metrics\n",
      "2025-05-07 15:41:38,629 - INFO - Overall accuracy: 0.8528\n",
      "2025-05-07 15:41:38,629 - INFO - Overall F1 score: 0.8506\n",
      "2025-05-07 15:41:38,630 - INFO - Class 'left' - Precision: 0.7820, Recall: 0.9351, F1: 0.8517\n",
      "2025-05-07 15:41:38,631 - INFO - Class 'center' - Precision: 0.9548, Recall: 0.7048, F1: 0.8110\n",
      "2025-05-07 15:41:38,632 - INFO - Class 'right' - Precision: 0.8616, Recall: 0.9186, F1: 0.8892\n",
      "2025-05-07 15:41:39,084 - INFO - Saving model\n",
      "2025-05-07 15:41:39,434 - INFO - Model saved to ./opt_models/naive_bayes_model.joblib\n",
      "2025-05-07 15:41:39,435 - INFO - Performing error analysis\n",
      "2025-05-07 15:41:50,407 - INFO - Error rate: 0.1472 (2305/15660)\n",
      "2025-05-07 15:41:50,408 - INFO - Error analysis saved to ./opt_results/error_analysis.csv\n",
      "2025-05-07 15:41:50,412 - INFO - Making predictions\n",
      "2025-05-07 15:41:50,413 - INFO - Predicting batch 1/40\n",
      "2025-05-07 15:41:51,058 - INFO - Predicting batch 2/40\n",
      "2025-05-07 15:41:51,681 - INFO - Predicting batch 3/40\n",
      "2025-05-07 15:41:52,320 - INFO - Predicting batch 4/40\n",
      "2025-05-07 15:41:52,914 - INFO - Predicting batch 5/40\n",
      "2025-05-07 15:41:53,528 - INFO - Predicting batch 6/40\n",
      "2025-05-07 15:41:54,134 - INFO - Predicting batch 7/40\n",
      "2025-05-07 15:41:54,743 - INFO - Predicting batch 8/40\n",
      "2025-05-07 15:41:55,344 - INFO - Predicting batch 9/40\n",
      "2025-05-07 15:41:56,127 - INFO - Predicting batch 10/40\n",
      "2025-05-07 15:41:56,752 - INFO - Predicting batch 11/40\n",
      "2025-05-07 15:41:57,325 - INFO - Predicting batch 12/40\n",
      "2025-05-07 15:41:57,892 - INFO - Predicting batch 13/40\n",
      "2025-05-07 15:41:58,465 - INFO - Predicting batch 14/40\n",
      "2025-05-07 15:41:59,015 - INFO - Predicting batch 15/40\n",
      "2025-05-07 15:41:59,624 - INFO - Predicting batch 16/40\n",
      "2025-05-07 15:42:00,218 - INFO - Predicting batch 17/40\n",
      "2025-05-07 15:42:00,811 - INFO - Predicting batch 18/40\n",
      "2025-05-07 15:42:01,402 - INFO - Predicting batch 19/40\n",
      "2025-05-07 15:42:01,968 - INFO - Predicting batch 20/40\n",
      "2025-05-07 15:42:02,569 - INFO - Predicting batch 21/40\n",
      "2025-05-07 15:42:03,143 - INFO - Predicting batch 22/40\n",
      "2025-05-07 15:42:03,686 - INFO - Predicting batch 23/40\n",
      "2025-05-07 15:42:04,232 - INFO - Predicting batch 24/40\n",
      "2025-05-07 15:42:04,838 - INFO - Predicting batch 25/40\n",
      "2025-05-07 15:42:05,476 - INFO - Predicting batch 26/40\n",
      "2025-05-07 15:42:06,104 - INFO - Predicting batch 27/40\n",
      "2025-05-07 15:42:06,700 - INFO - Predicting batch 28/40\n",
      "2025-05-07 15:42:07,302 - INFO - Predicting batch 29/40\n",
      "2025-05-07 15:42:07,868 - INFO - Predicting batch 30/40\n",
      "2025-05-07 15:42:08,486 - INFO - Predicting batch 31/40\n",
      "2025-05-07 15:42:09,079 - INFO - Predicting batch 32/40\n",
      "2025-05-07 15:42:09,658 - INFO - Predicting batch 33/40\n",
      "2025-05-07 15:42:10,251 - INFO - Predicting batch 34/40\n",
      "2025-05-07 15:42:10,800 - INFO - Predicting batch 35/40\n",
      "2025-05-07 15:42:11,338 - INFO - Predicting batch 36/40\n",
      "2025-05-07 15:42:11,874 - INFO - Predicting batch 37/40\n",
      "2025-05-07 15:42:12,443 - INFO - Predicting batch 38/40\n",
      "2025-05-07 15:42:12,986 - INFO - Predicting batch 39/40\n",
      "2025-05-07 15:42:13,551 - INFO - Predicting batch 40/40\n",
      "2025-05-07 15:42:18,162 - INFO - Results saved to ./opt_results/predictions.csv\n",
      "2025-05-07 15:42:18,203 - INFO - Confidence stats: {'mean_confidence': 0.9756754666382372, 'std_confidence': 0.08024009914944923, 'min_confidence': 0.3333333333333333, 'max_confidence': 1.0}\n",
      "2025-05-07 15:42:18,236 - INFO - Pipeline completed successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
    "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "OUTPUT_DIR = \"./opt_results\"\n",
    "LOGGING_DIR = \"./opt_logs\"\n",
    "MODELS_DIR = \"./opt_models\"\n",
    "RESULTS_PATH = os.path.join(OUTPUT_DIR, \"predictions.csv\")\n",
    "ERROR_ANALYSIS_PATH = os.path.join(OUTPUT_DIR, \"error_analysis.csv\")\n",
    "CHUNK_SIZE = 2000  # Chunk size for memory efficiency\n",
    "\n",
    "# Ensure directories exist\n",
    "for directory in [OUTPUT_DIR, LOGGING_DIR, MODELS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Custom Tokenizer for Production\n",
    "def custom_tokenizer(text):\n",
    "    \"\"\"Efficient regex-based tokenizer for production use.\"\"\"\n",
    "    # Clean text: remove URLs, numbers, special characters\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+|[^\\w\\s]|\\d+', ' ', text.lower())\n",
    "    # Tokenize by whitespace and filter tokens\n",
    "    tokens = [token for token in text.split() if len(token) > 2 and token not in ENGLISH_STOP_WORDS]\n",
    "    return tokens\n",
    "\n",
    "# Text Processing Functions\n",
    "def clean_text(text):\n",
    "    \"\"\"Efficient text cleaning function.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text) if text else \"\"\n",
    "    \n",
    "    # Clean with regex\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+|<.*?>|[^\\w\\s]|\\d+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def combine_text(df, text_cols):\n",
    "    \"\"\"Combine text columns into a single 'combined_input' column.\"\"\"\n",
    "    # Ensure all text columns exist\n",
    "    available_cols = [col for col in text_cols if col in df]\n",
    "    for col in set(text_cols) - set(available_cols):\n",
    "        df[col] = \"\"\n",
    "    \n",
    "    # Apply cleaning to text columns\n",
    "    for col in available_cols:\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "    \n",
    "    # Combine text columns with weights\n",
    "    weights = {'text': 2, 'article': 2, 'topic': 1, 'biased_words': 1.5}\n",
    "    def weighted_combine(row):\n",
    "        combined = \"\"\n",
    "        for col in available_cols:\n",
    "            weight = int(weights.get(col, 1))\n",
    "            combined += (\" \" + str(row[col]) + \" \") * weight\n",
    "        return combined.strip()\n",
    "    \n",
    "    df[\"combined_input\"] = df[available_cols].apply(weighted_combine, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute evaluation metrics.\"\"\"\n",
    "    logger.info(\"Computing metrics\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Compute per-class metrics\n",
    "    class_precision, class_recall, class_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": acc, \n",
    "        \"f1\": f1, \n",
    "        \"precision\": precision, \n",
    "        \"recall\": recall,\n",
    "        \"class_precision\": {REVERSE_LABEL_MAP[i]: p for i, p in enumerate(class_precision)},\n",
    "        \"class_recall\": {REVERSE_LABEL_MAP[i]: r for i, r in enumerate(class_recall)},\n",
    "        \"class_f1\": {REVERSE_LABEL_MAP[i]: f for i, f in enumerate(class_f1)},\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    logger.info(f\"Overall accuracy: {acc:.4f}\")\n",
    "    logger.info(f\"Overall F1 score: {f1:.4f}\")\n",
    "    for i, label in REVERSE_LABEL_MAP.items():\n",
    "        logger.info(f\"Class '{label}' - Precision: {class_precision[i]:.4f}, \"\n",
    "                   f\"Recall: {class_recall[i]:.4f}, F1: {class_f1[i]:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Chunked Data Processing\n",
    "def process_chunks(file_path, process_fn):\n",
    "    \"\"\"Process data in chunks and collect results.\"\"\"\n",
    "    results = []\n",
    "    for chunk in pd.read_csv(file_path, chunksize=CHUNK_SIZE):\n",
    "        processed = process_fn(chunk)\n",
    "        results.append(processed)\n",
    "    return pd.concat(results)\n",
    "\n",
    "def preprocess_chunk(chunk):\n",
    "    \"\"\"Preprocess a single chunk of data.\"\"\"\n",
    "    chunk = chunk[chunk[\"type\"].isin(LABEL_MAP.keys())].copy()\n",
    "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
    "    chunk_processed = combine_text(chunk, text_cols)\n",
    "    chunk_processed[\"label\"] = chunk_processed[\"type\"].map(LABEL_MAP)\n",
    "    return chunk_processed\n",
    "\n",
    "# Error Analysis\n",
    "def perform_error_analysis(model, eval_df, X_eval, y_eval):\n",
    "    \"\"\"Analyze prediction errors.\"\"\"\n",
    "    logger.info(\"Performing error analysis\")\n",
    "    \n",
    "    y_pred = model.predict(X_eval)\n",
    "    y_proba = model.predict_proba(X_eval)\n",
    "    \n",
    "    error_df = eval_df.copy()\n",
    "    error_df['true_label'] = error_df['label'].map(REVERSE_LABEL_MAP)\n",
    "    error_df['predicted_label'] = [REVERSE_LABEL_MAP[p] for p in y_pred]\n",
    "    error_df['correct'] = error_df['label'] == y_pred\n",
    "    \n",
    "    # Add confidence scores\n",
    "    for i, label in REVERSE_LABEL_MAP.items():\n",
    "        error_df[f'confidence_{label}'] = y_proba[:, i]\n",
    "    error_df['confidence'] = [y_proba[i, pred] for i, pred in enumerate(y_pred)]\n",
    "    \n",
    "    # Save errors\n",
    "    errors_only = error_df[~error_df['correct']].sort_values('confidence')\n",
    "    errors_only.to_csv(ERROR_ANALYSIS_PATH, index=False)\n",
    "    \n",
    "    error_count = (~error_df['correct']).sum()\n",
    "    error_rate = error_count / len(error_df)\n",
    "    logger.info(f\"Error rate: {error_rate:.4f} ({error_count}/{len(error_df)})\")\n",
    "    logger.info(f\"Error analysis saved to {ERROR_ANALYSIS_PATH}\")\n",
    "    \n",
    "    return errors_only\n",
    "\n",
    "# Prediction Function\n",
    "def predict_in_chunks(model, full_df, batch_size=2000):\n",
    "    \"\"\"Make predictions in batches with confidence scores.\"\"\"\n",
    "    all_preds = []\n",
    "    all_confidence = []\n",
    "    \n",
    "    for i in range(0, len(full_df), batch_size):\n",
    "        logger.info(f\"Predicting batch {i//batch_size + 1}/{(len(full_df)//batch_size)+1}\")\n",
    "        chunk = full_df.iloc[i:i+batch_size]\n",
    "        \n",
    "        proba = model.predict_proba(chunk[\"combined_input\"])\n",
    "        pred_class = np.argmax(proba, axis=1)\n",
    "        confidence = np.max(proba, axis=1)\n",
    "        \n",
    "        preds = [REVERSE_LABEL_MAP[p] for p in pred_class]\n",
    "        \n",
    "        all_preds.extend(preds)\n",
    "        all_confidence.extend(confidence)\n",
    "    \n",
    "    return all_preds, all_confidence\n",
    "\n",
    "# Main Pipeline\n",
    "def main(file_path, vectorizer_type='count', classifier_type='naive_bayes', grid_search=True):\n",
    "    \"\"\"Main pipeline for Naive Bayes classification with optimized vectorizer.\"\"\"\n",
    "    logger.info(f\"Starting Naive Bayes pipeline with {vectorizer_type} vectorizer\")\n",
    "    \n",
    "    # 1. Load and preprocess data in chunks\n",
    "    logger.info(\"Loading and preprocessing data in chunks\")\n",
    "    full_df = process_chunks(file_path, preprocess_chunk)\n",
    "    \n",
    "    # Save processed data\n",
    "    processed_data_path = os.path.join(OUTPUT_DIR, \"processed_data.parquet\")\n",
    "    full_df.to_parquet(processed_data_path, index=False)\n",
    "    logger.info(f\"Saved processed data to {processed_data_path}\")\n",
    "    \n",
    "    # 2. Train-test split\n",
    "    logger.info(\"Splitting data into train and eval sets\")\n",
    "    train_df, eval_df = train_test_split(\n",
    "        full_df, \n",
    "        test_size=0.2, \n",
    "        stratify=full_df[\"label\"], \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 3. Prepare data\n",
    "    logger.info(\"Preparing data\")\n",
    "    X_train = train_df[\"combined_input\"]\n",
    "    y_train = train_df[\"label\"].values\n",
    "    X_eval = eval_df[\"combined_input\"]\n",
    "    y_eval = eval_df[\"label\"].values\n",
    "    \n",
    "    # 4. Build pipeline\n",
    "    logger.info(\"Setting up Naive Bayes pipeline\")\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=10000,\n",
    "        min_df=3,\n",
    "        max_df=0.9,\n",
    "        ngram_range=(1, 2),\n",
    "        tokenizer=custom_tokenizer,\n",
    "        stop_words=None  # Stop words handled in custom tokenizer\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    # 5. Hyperparameter tuning\n",
    "    if grid_search:\n",
    "        logger.info(\"Performing hyperparameter tuning\")\n",
    "        param_grid = {\n",
    "            'vectorizer__max_features': [5000, 10000],\n",
    "            'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "            'clf__alpha': [0.1, 0.5, 1.0]\n",
    "        }\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,\n",
    "            scoring='f1_weighted',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Training with GridSearchCV\")\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        pipeline = grid_search.best_estimator_\n",
    "        logger.info(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        logger.info(\"Training without hyperparameter tuning\")\n",
    "        pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. Evaluate model\n",
    "    logger.info(\"Evaluating model\")\n",
    "    y_pred = pipeline.predict(X_eval)\n",
    "    metrics = compute_metrics(y_eval, y_pred)\n",
    "    plot_confusion_matrix(metrics[\"confusion_matrix\"], list(LABEL_MAP.keys()))\n",
    "    \n",
    "    # 7. Save model\n",
    "    logger.info(\"Saving model\")\n",
    "    model_path = os.path.join(MODELS_DIR, \"naive_bayes_model.joblib\")\n",
    "    dump(pipeline, model_path)\n",
    "    logger.info(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # 8. Error analysis\n",
    "    error_analysis = perform_error_analysis(pipeline, eval_df, X_eval, y_eval)\n",
    "    \n",
    "    # 9. Make predictions\n",
    "    logger.info(\"Making predictions\")\n",
    "    predictions, confidence_scores = predict_in_chunks(pipeline, full_df)\n",
    "    full_df[\"predicted_bias_category\"] = predictions\n",
    "    full_df[\"confidence_score\"] = confidence_scores\n",
    "    \n",
    "    # 10. Save results\n",
    "    full_df.to_csv(RESULTS_PATH, index=False)\n",
    "    logger.info(f\"Results saved to {RESULTS_PATH}\")\n",
    "    \n",
    "    # 11. Compute confidence statistics\n",
    "    confidence_stats = {\n",
    "        \"mean_confidence\": np.mean(confidence_scores),\n",
    "        \"std_confidence\": np.std(confidence_scores),\n",
    "        \"min_confidence\": np.min(confidence_scores),\n",
    "        \"max_confidence\": np.max(confidence_scores)\n",
    "    }\n",
    "    logger.info(f\"Confidence stats: {confidence_stats}\")\n",
    "    \n",
    "    return full_df, confidence_stats, error_analysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file_path = \"complete_balanced_data.csv\"\n",
    "    results_df, confidence_stats, error_analysis = main(\n",
    "        input_file_path, \n",
    "        vectorizer_type='count',\n",
    "        classifier_type='naive_bayes',\n",
    "        grid_search=True\n",
    "    )\n",
    "    logger.info(\"Pipeline completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 16:30:40,128 - INFO - Starting sample prediction pipeline with confidence scores\n",
      "2025-05-07 16:30:40,129 - INFO - Preprocessing samples\n",
      "2025-05-07 16:30:40,131 - INFO - Loading trained Naive Bayes model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 16:30:40,326 - INFO - Making predictions on samples\n",
      "2025-05-07 16:30:40,334 - INFO - Sample predictions saved to ./opt_results/sample_predictions.csv\n",
      "2025-05-07 16:30:40,335 - INFO - Sample 1:\n",
      "2025-05-07 16:30:40,336 - INFO - Predicted Bias: left \n",
      " confidence score: (1.0000)\n",
      "2025-05-07 16:30:40,337 - INFO - Sample text (truncated): as wildfires rage across california, floods displace thousands in the midwest, and heatwaves scorch ...\n",
      "2025-05-07 16:30:40,338 - INFO - Sample 2:\n",
      "2025-05-07 16:30:40,339 - INFO - Predicted Bias: right \n",
      " confidence score: (1.0000)\n",
      "2025-05-07 16:30:40,339 - INFO - Sample text (truncated): the united states thrives when government steps back and lets free enterprise lead. in recent years,...\n",
      "2025-05-07 16:30:40,341 - INFO - Sample 3:\n",
      "2025-05-07 16:30:40,341 - INFO - Predicted Bias: center \n",
      " confidence score: (0.8471)\n",
      "2025-05-07 16:30:40,342 - INFO - Sample text (truncated): as artificial intelligence tools become increasingly integrated into everyday life—from health diagn...\n",
      "2025-05-07 16:30:40,343 - INFO - Sample 4:\n",
      "2025-05-07 16:30:40,344 - INFO - Predicted Bias: right \n",
      " confidence score: (0.9999)\n",
      "2025-05-07 16:30:40,345 - INFO - Sample text (truncated): in yet another blow to working-class americans, senate republicans have blocked legislation that wou...\n",
      "2025-05-07 16:30:40,347 - INFO - Sample 5:\n",
      "2025-05-07 16:30:40,348 - INFO - Predicted Bias: right \n",
      " confidence score: (1.0000)\n",
      "2025-05-07 16:30:40,349 - INFO - Sample text (truncated): the southern border has long been a flashpoint in american politics, but recent data shows that toug...\n",
      "2025-05-07 16:30:40,350 - INFO - Sample prediction completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
    "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "MODEL_PATH = \"./opt_models/naive_bayes_model.joblib\"\n",
    "OUTPUT_PATH = \"./opt_results/sample_predictions.csv\"\n",
    "\n",
    "# Text Processing Function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by converting to lowercase and handling non-string inputs.\"\"\"\n",
    "    if isinstance(text, list):\n",
    "        return ' '.join(str(t).lower() for t in text if isinstance(t, str))\n",
    "    return str(text).lower()\n",
    "\n",
    "# Main Testing Function\n",
    "def test_samples(samples):\n",
    "    logger.info(\"Starting sample prediction pipeline with confidence scores\")\n",
    "    \n",
    "    # 1. Prepare samples as DataFrame\n",
    "    logger.info(\"Preprocessing samples\")\n",
    "    sample_df = pd.DataFrame({\n",
    "        \"combined_input\": [preprocess_text(sample[0]) for sample in samples]\n",
    "    })\n",
    "    \n",
    "    # 2. Load the trained model\n",
    "    logger.info(\"Loading trained Naive Bayes model\")\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        logger.error(f\"Model file not found at {MODEL_PATH}\")\n",
    "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}\")\n",
    "    \n",
    "    model = load(MODEL_PATH)\n",
    "    \n",
    "    # 3. Make predictions and get confidence scores\n",
    "    logger.info(\"Making predictions on samples\")\n",
    "    predictions = model.predict(sample_df[\"combined_input\"])\n",
    "    probabilities = model.predict_proba(sample_df[\"combined_input\"])\n",
    "    \n",
    "    # Extract confidence scores for predicted classes\n",
    "    confidence_scores = [prob[pred] for prob, pred in zip(probabilities, predictions)]\n",
    "    \n",
    "    # Add predictions and confidence scores to DataFrame\n",
    "    sample_df[\"predicted_bias_category\"] = [REVERSE_LABEL_MAP[p] for p in predictions]\n",
    "    sample_df[\"confidence_score\"] = confidence_scores\n",
    "    \n",
    "    # 4. Save results\n",
    "    sample_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    logger.info(f\"Sample predictions saved to {OUTPUT_PATH}\")\n",
    "    \n",
    "    # 5. Log predictions with confidence scores\n",
    "    for i, (text, pred, score) in enumerate(zip(sample_df[\"combined_input\"], sample_df[\"predicted_bias_category\"], sample_df[\"confidence_score\"])):\n",
    "        logger.info(f\"Sample {i+1}:\")\n",
    "        logger.info(f\"Predicted Bias: {pred} \\n confidence score: ({score:.4f})\")\n",
    "        logger.info(f\"Sample text (truncated): {text[:100]}...\")\n",
    "    \n",
    "    return sample_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provided samples\n",
    "    samples = [\n",
    "        [\"\"\"As wildfires rage across California, floods displace thousands in the Midwest, and heatwaves scorch cities from Texas to New York, the evidence is undeniable: the climate crisis is no longer a distant threat—it’s here. And yet, as communities suffer and ecosystems collapse, fossil fuel corporations continue to post record-breaking profits, protected by conservative politicians and a global system rigged in their favor.\n",
    "        In 2024 alone, the five largest oil companies reported over $200 billion in profits. Instead of investing in renewable energy or helping vulnerable communities transition to a green economy, these corporations funneled billions into stock buybacks and executive bonuses. Their message is clear: profits come before people, and the planet can burn so long as the shareholders stay rich.\n",
    "        Even more alarming is the political shielding they receive from right-wing lawmakers, many of whom deny climate science altogether. Republican leaders in Congress have repeatedly blocked climate legislation, gutted the Environmental Protection Agency’s regulatory powers, and prioritized drilling permits over clean air and water.\n",
    "        Meanwhile, climate activists—many of them youth, Indigenous leaders, and marginalized communities—continue to face police repression, surveillance, and criminalization. Peaceful protesters at pipeline sites are arrested, while oil spills and environmental destruction go unpunished.\n",
    "        We need a Green New Deal-level transformation: bold investments in wind, solar, and green infrastructure; the creation of millions of unionized green jobs; and climate reparations for communities hit hardest by pollution and environmental racism.\n",
    "        The time for delay is over. The time to act is now.\"\"\"],\n",
    "        [\"\"\"The United States thrives when government steps back and lets free enterprise lead. In recent years, however, progressive lawmakers have increasingly pushed for regulation, redistribution, and intervention that stifles innovation and discourages hard work.\n",
    "        From overreaching environmental mandates to government-controlled healthcare proposals, the left continues to champion policies that prioritize bureaucracy over results. These moves are not only anti-business—they’re anti-American.\n",
    "        America's economic engine runs best when the private sector is free to create, compete, and grow. Small business owners across the country are already struggling with inflation and labor shortages—problems worsened by excessive government interference and rising taxes.\n",
    "        We must return to policies that reward productivity, protect property rights, and uphold free-market values. Deregulation, tax reform, and energy independence will not only restore our economy—they’ll renew our national spirit.\"\"\"],\n",
    "        [\"\"\"As artificial intelligence tools become increasingly integrated into everyday life—from health diagnostics to criminal justice systems—Democratic and Republican lawmakers alike are recognizing the need for clear regulatory frameworks.\n",
    "        A bipartisan group in Congress recently introduced the American AI Responsibility Act, aiming to address transparency, data privacy, and algorithmic bias. While the bill doesn’t go as far as some activists demand, it marks an important step toward balancing innovation with accountability.\n",
    "        Tech CEOs have expressed cautious support, stating that some regulation is needed to maintain public trust, but they warn against overregulation that could drive development offshore.\n",
    "        Experts agree: regulation must be careful, measured, and informed by the science—not by political theater. While divisions remain, the shared concern over AI’s risks may offer a rare opportunity for consensus in Washington.\"\"\"],\n",
    "        [\"\"\"In yet another blow to working-class Americans, Senate Republicans have blocked legislation that would raise the federal minimum wage to $17 per hour by 2027. With wages stagnant and inflation hitting food, rent, and transportation costs, the move is being widely condemned by labor leaders and economists.\n",
    "        The current $7.25 minimum wage has not been raised since 2009, despite historic gains in productivity and corporate profits. Over 60% of Americans support a raise, but Republican lawmakers claim it would “hurt small businesses”—an argument that many economists say is overblown.\n",
    "        In reality, the refusal to raise wages preserves exploitative systems where billion-dollar corporations rely on underpaid workers while CEO salaries skyrocket.\n",
    "        This is not just about economics—it’s about dignity. Every American who works full-time should be able to afford basic necessities. Congress’s failure to act is a moral failure, and it’s up to voters to hold them accountable.\"\"\"],\n",
    "        [\"\"\"The southern border has long been a flashpoint in American politics, but recent data shows that tougher enforcement and advanced surveillance technology are yielding results. Illegal crossings dropped 30% in the first quarter of 2025 compared to the previous year, according to Homeland Security reports.\n",
    "        Under the new measures, authorities have deployed AI-powered drones, reinforced border fencing, and accelerated asylum screening procedures. Critics on the left say the policies are “inhumane,” but officials argue they are necessary to protect national sovereignty and public safety.\n",
    "        Drug seizures have also increased, particularly fentanyl shipments originating from cartels that exploit weak border points. Law enforcement agencies say the new tools and funding are making a significant impact.\n",
    "        The Biden administration was slow to act early in its term, but this policy shift marks a necessary correction. The right to immigrate must be balanced with the rule of law—and American citizens deserve to feel safe and secure in their own country.\"\"\"]\n",
    "    ]\n",
    "    \n",
    "    # Run the prediction\n",
    "    results_df = test_samples(samples)\n",
    "    logger.info(\"Sample prediction completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
