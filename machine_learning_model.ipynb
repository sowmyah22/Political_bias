{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhAX7zB1VH2y",
        "outputId": "7106e96e-440d-4539-e1e2-6ba1300d6ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kKTaJ_0Wqp9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import logging\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkjGJ0L0eSz9"
      },
      "source": [
        "### Ensemble model - logistic,rf,xgb,lgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nBdYoFtWjot",
        "outputId": "1029a00c-a7bb-4ec2-881f-6c4c3fa5c06f",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:57:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results\"\n",
        "LOGGING_DIR = \"/content/drive/MyDrive/Colab Notebooks/logs\"\n",
        "RESULTS_PATH = \"/content/drive/MyDrive/Colab Notebooks/predictions.csv\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model.pkl\")\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LOGGING_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(RESULTS_PATH), exist_ok=True)\n",
        "\n",
        "# ---------------- Text Processing Functions ----------------\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(str(t).lower() for t in text if isinstance(t, str)) if isinstance(text, list) else str(text).lower()\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
        "    df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
        "    return df\n",
        "\n",
        "# ---------------- Load & Preprocess ----------------\n",
        "def load_and_preprocess(file_path):\n",
        "    logger.info(\"Loading and preprocessing data\")\n",
        "    df = pd.read_excel(file_path, engine='openpyxl')\n",
        "    df = df[df[\"type\"].isin(LABEL_MAP.keys())]\n",
        "\n",
        "    logger.info(\"Original distribution:\")\n",
        "    logger.info(df[\"type\"].value_counts())\n",
        "\n",
        "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
        "    df_processed = combine_text(df, text_cols)\n",
        "    df_processed[\"label\"] = df_processed[\"type\"].map(LABEL_MAP)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# ---------------- Metrics ----------------\n",
        "def compute_metrics(labels, preds):\n",
        "    logger.info(\"Computing metrics\")\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# ---------------- Main Pipeline ----------------\n",
        "def main(file_path):\n",
        "    logger.info(\"Starting main pipeline\")\n",
        "    # Load and prepare data\n",
        "    df = load_and_preprocess(file_path)\n",
        "\n",
        "    # Train-Test Split\n",
        "    logger.info(\"Splitting data\")\n",
        "    train_df, eval_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "    # Create a pipeline with TF-IDF\n",
        "    logger.info(\"Setting up pipeline with TF-IDF\")\n",
        "    tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "\n",
        "    # Transform text to TF-IDF features\n",
        "    logger.info(\"Transforming training data to TF-IDF\")\n",
        "    X_train_tfidf = tfidf.fit_transform(train_df[\"combined_input\"])\n",
        "    X_eval_tfidf = tfidf.transform(eval_df[\"combined_input\"])\n",
        "\n",
        "    # Apply SMOTE to balance the training data\n",
        "    logger.info(\"Applying SMOTE for balancing\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, train_df[\"label\"])\n",
        "\n",
        "    logger.info(\"Original train distribution:\")\n",
        "    logger.info(train_df[\"type\"].value_counts())\n",
        "    logger.info(\"Balanced train distribution:\")\n",
        "    logger.info(pd.Series(y_train_res).map(REVERSE_LABEL_MAP).value_counts())\n",
        "\n",
        "    # Define individual models\n",
        "    logger.info(\"Setting up ensemble models\")\n",
        "    logistic = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "    lgbm = LGBMClassifier(random_state=42, verbose=-1)\n",
        "\n",
        "    # Create the ensemble with soft voting\n",
        "    ensemble = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('logistic', logistic),\n",
        "            ('rf', rf),\n",
        "            ('xgb', xgb),\n",
        "            ('lgbm', lgbm)\n",
        "        ],\n",
        "        voting='soft'  # Use soft voting to average probabilities\n",
        "    )\n",
        "\n",
        "    # Train the ensemble model\n",
        "    logger.info(\"Training ensemble model\")\n",
        "    ensemble.fit(X_train_res, y_train_res)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    logger.info(\"Evaluating model\")\n",
        "    eval_preds = ensemble.predict(X_eval_tfidf)\n",
        "    metrics = compute_metrics(eval_df[\"label\"], eval_preds)\n",
        "    logger.info(\"Evaluation Metrics:\")\n",
        "    logger.info(metrics)\n",
        "\n",
        "    # Save the model and TF-IDF vectorizer\n",
        "    logger.info(\"Saving model\")\n",
        "    with open(MODEL_PATH, 'wb') as f:\n",
        "        pickle.dump({'ensemble': ensemble, 'tfidf': tfidf}, f)\n",
        "    logger.info(f\"Model saved to {MODEL_PATH}\")\n",
        "\n",
        "    # Prediction on full dataset\n",
        "    logger.info(\"Making predictions\")\n",
        "    X_full_tfidf = tfidf.transform(df[\"combined_input\"])\n",
        "    pred_labels = ensemble.predict(X_full_tfidf)\n",
        "    df[\"predicted_bias_category\"] = [REVERSE_LABEL_MAP[i] for i in pred_labels]\n",
        "    df.to_csv(RESULTS_PATH, index=False)\n",
        "    logger.info(f\"Predictions saved to {RESULTS_PATH}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file_path = \"/content/drive/MyDrive/Colab Notebooks/combined_data.xlsx\"\n",
        "    main(input_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkn3hqvtZp3e"
      },
      "source": [
        "### Test the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd4y6QO9bl_f",
        "outputId": "30d95112-ddae-40aa-8aba-a5d0b767f33d",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Text: the government must provide universal healthcare to ensure equality for all citizens....\n",
            "True Bias: left | Predicted: right (0.54)\n",
            "\n",
            "Text: the new policy aims to balance economic growth with environmental sustainability....\n",
            "True Bias: center | Predicted: right (0.46)\n",
            "\n",
            "Text: lower taxes and deregulation are key to boosting economic freedom and growth....\n",
            "True Bias: right | Predicted: right (0.47)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model.pkl\")\n",
        "\n",
        "# Mount Google Drive (for Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)  # Ensure the directory exists\n",
        "except ImportError:\n",
        "    logger.info(\"Not running in Colab; skipping drive mount.\")\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create directory if not in Colab\n",
        "\n",
        "# ---------------- Text Processing Functions ----------------\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(str(t).lower() for t in text if isinstance(t, str)) if isinstance(text, list) else str(text).lower()\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
        "    df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
        "    return df\n",
        "\n",
        "# ---------------- Load Model and TF-IDF ----------------\n",
        "def load_model():\n",
        "    logger.info(f\"Attempting to load model from {MODEL_PATH}\")\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        logger.error(f\"Model file not found at {MODEL_PATH}. Please upload the file 'ensemble_model.pkl' to this directory.\")\n",
        "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}. Please ensure the file is uploaded to {OUTPUT_DIR}.\")\n",
        "    with open(MODEL_PATH, 'rb') as f:\n",
        "        saved_data = pickle.load(f)\n",
        "    return saved_data['ensemble'], saved_data['tfidf']\n",
        "\n",
        "# ---------------- Test with Sample Data ----------------\n",
        "def test_model():\n",
        "    # Create sample data with true labels\n",
        "    sample_data = pd.DataFrame({\n",
        "        \"text\": [\n",
        "            \"The government must provide universal healthcare to ensure equality for all citizens.\",\n",
        "            \"The new policy aims to balance economic growth with environmental sustainability.\",\n",
        "            \"Lower taxes and deregulation are key to boosting economic freedom and growth.\"\n",
        "        ],\n",
        "        \"topic\": [\"Healthcare\", \"Policy\", \"Economy\"],\n",
        "        \"article\": [\"\", \"\", \"\"],\n",
        "        \"biased_words\": [\"equality\", \"balance\", \"freedom\"],\n",
        "        \"true_bias\": [\"left\", \"center\", \"right\"]  # Hypothetical true labels\n",
        "    })\n",
        "\n",
        "    logger.info(\"Sample data created:\")\n",
        "    logger.info(sample_data)\n",
        "\n",
        "    # Preprocess sample data\n",
        "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
        "    sample_data_processed = combine_text(sample_data, text_cols)\n",
        "\n",
        "    # Load model and TF-IDF vectorizer\n",
        "    ensemble, tfidf = load_model()\n",
        "\n",
        "    # Transform sample data to TF-IDF features\n",
        "    logger.info(\"Transforming sample data to TF-IDF features\")\n",
        "    X_sample_tfidf = tfidf.transform(sample_data_processed[\"combined_input\"])\n",
        "\n",
        "    # Make predictions and get probabilities\n",
        "    logger.info(\"Making predictions\")\n",
        "    pred_labels = ensemble.predict(X_sample_tfidf)\n",
        "    pred_probs = ensemble.predict_proba(X_sample_tfidf)\n",
        "    confidences = np.max(pred_probs, axis=1)  # Take the maximum probability as confidence\n",
        "\n",
        "    # Add predictions and confidences to the DataFrame\n",
        "    sample_data[\"predicted_bias_category\"] = [REVERSE_LABEL_MAP[i] for i in pred_labels]\n",
        "    sample_data[\"confidence\"] = confidences\n",
        "\n",
        "    # Print formatted output for each sample\n",
        "    for index, row in sample_data.iterrows():\n",
        "        text = row[\"text\"]\n",
        "        true_label = row[\"true_bias\"]\n",
        "        readable_label = row[\"predicted_bias_category\"]\n",
        "        confidence = row[\"confidence\"]\n",
        "        print(f\"\\nText: {text[:100]}...\")\n",
        "        print(f\"True Bias: {true_label} | Predicted: {readable_label} ({confidence:.2f})\")\n",
        "\n",
        "    return sample_data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    result = test_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvE8NqzpcRqc",
        "outputId": "1ca6f21f-6bab-4bea-9cf6-2eb72462037f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-282d4f1e1fd3>:64: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sample_rows[col] = \"\"\n",
            "<ipython-input-2-282d4f1e1fd3>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
            "<ipython-input-2-282d4f1e1fd3>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: right (0.84)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.68)\n",
            "\n",
            "Text: ...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. white...\n",
            "True Bias: left | Predicted: left (0.84)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model.pkl\")\n",
        "TEST_FILE_PATH = \"/content/drive/MyDrive/Colab Notebooks/test_sample.xlsx\"\n",
        "\n",
        "# Mount Google Drive (for Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)  # Ensure the directory exists\n",
        "except ImportError:\n",
        "    logger.info(\"Not running in Colab; skipping drive mount.\")\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create directory if not in Colab\n",
        "\n",
        "# ---------------- Text Processing Functions ----------------\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(str(t).lower() for t in text if isinstance(t, str)) if isinstance(text, list) else str(text).lower()\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
        "    df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
        "    return df\n",
        "\n",
        "# ---------------- Load Model and TF-IDF ----------------\n",
        "def load_model():\n",
        "    logger.info(f\"Attempting to load model from {MODEL_PATH}\")\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        logger.error(f\"Model file not found at {MODEL_PATH}. Please upload the file 'ensemble_model.pkl' to this directory.\")\n",
        "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}. Please ensure the file is uploaded to {OUTPUT_DIR}.\")\n",
        "    with open(MODEL_PATH, 'rb') as f:\n",
        "        saved_data = pickle.load(f)\n",
        "    return saved_data['ensemble'], saved_data['tfidf']\n",
        "\n",
        "# ---------------- Test with New Data ----------------\n",
        "def test_new_data():\n",
        "    # Load the test file\n",
        "    logger.info(f\"Loading test data from {TEST_FILE_PATH}\")\n",
        "    df_test = pd.read_excel(TEST_FILE_PATH, engine='openpyxl')\n",
        "\n",
        "    # Preview columns\n",
        "    logger.info(\"Columns in the test dataset:\")\n",
        "    logger.info(df_test.columns)\n",
        "\n",
        "    # Use first 30 rows for testing\n",
        "    sample_rows = df_test.head(30)\n",
        "\n",
        "    # Ensure required columns exist, fill with empty strings if missing\n",
        "    required_cols = [\"sentence\", \"topic\", \"article\", \"biased_words\"]\n",
        "    for col in required_cols:\n",
        "        if col not in sample_rows.columns:\n",
        "            sample_rows[col] = \"\"\n",
        "    if 'type' not in sample_rows.columns:\n",
        "        sample_rows['type'] = \"Unknown\"\n",
        "\n",
        "    # Preprocess sample data\n",
        "    text_cols = [\"sentence\", \"topic\", \"article\", \"biased_words\"]\n",
        "    sample_data_processed = combine_text(sample_rows, text_cols)\n",
        "\n",
        "    # Load model and TF-IDF vectorizer\n",
        "    ensemble, tfidf = load_model()\n",
        "\n",
        "    # Transform sample data to TF-IDF features\n",
        "    logger.info(\"Transforming sample data to TF-IDF features\")\n",
        "    X_sample_tfidf = tfidf.transform(sample_data_processed[\"combined_input\"])\n",
        "\n",
        "    # Make predictions and get probabilities\n",
        "    logger.info(\"Making predictions\")\n",
        "    pred_labels = ensemble.predict(X_sample_tfidf)\n",
        "    pred_probs = ensemble.predict_proba(X_sample_tfidf)\n",
        "    confidences = np.max(pred_probs, axis=1)  # Take the maximum probability as confidence\n",
        "\n",
        "    # Print formatted output for each sample\n",
        "    for idx, (index, row) in enumerate(sample_rows.iterrows()):\n",
        "        text = row[\"sentence\"]\n",
        "        true_label = row[\"type\"]\n",
        "        readable_label = REVERSE_LABEL_MAP[pred_labels[idx]]\n",
        "        confidence = confidences[idx]\n",
        "        print(f\"\\nText: {text[:100]}...\")\n",
        "        print(f\"True Bias: {true_label} | Predicted: {readable_label} ({confidence:.2f})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_new_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ9hKJ1GeKR8"
      },
      "source": [
        "### With optimization anf hyperparameter tuning methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSFusMrge7pk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90sAnoO1g6HG",
        "outputId": "dae3039e-d5f7-442c-c9b2-293829b06b7d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:05:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:12:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results_opt\"\n",
        "LOGGING_DIR = \"/content/drive/MyDrive/Colab Notebooks/logs_opt\"\n",
        "RESULTS_PATH = \"/content/drive/MyDrive/Colab Notebooks/predictions_bias.csv\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model_bias.pkl\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LOGGING_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(RESULTS_PATH), exist_ok=True)\n",
        "\n",
        "# ---------------- Text Processing Functions ----------------\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(str(t).lower() for t in text if isinstance(t, str)) if isinstance(text, list) else str(text).lower()\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
        "    df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
        "    return df\n",
        "\n",
        "# ---------------- Load & Preprocess ----------------\n",
        "def load_and_preprocess(file_path):\n",
        "    logger.info(\"Loading and preprocessing data\")\n",
        "    df = pd.read_excel(file_path, engine='openpyxl')\n",
        "    df = df[df[\"type\"].isin(LABEL_MAP.keys())]\n",
        "\n",
        "    logger.info(\"Original distribution:\")\n",
        "    logger.info(df[\"type\"].value_counts())\n",
        "\n",
        "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
        "    df_processed = combine_text(df, text_cols)\n",
        "    df_processed[\"label\"] = df_processed[\"type\"].map(LABEL_MAP)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# ---------------- Metrics ----------------\n",
        "def compute_metrics(labels, preds):\n",
        "    logger.info(\"Computing metrics\")\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# ---------------- Main Pipeline with Optimization ----------------\n",
        "def main(file_path):\n",
        "    logger.info(\"Starting main pipeline\")\n",
        "    # Load and prepare data\n",
        "    df = load_and_preprocess(file_path)\n",
        "\n",
        "    # Train-Test Split\n",
        "    logger.info(\"Splitting data\")\n",
        "    train_df, eval_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "    # Create a pipeline with TF-IDF with optimized features\n",
        "    logger.info(\"Setting up pipeline with TF-IDF\")\n",
        "    tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2), min_df=5)\n",
        "\n",
        "    # Transform text to TF-IDF features\n",
        "    logger.info(\"Transforming training data to TF-IDF\")\n",
        "    X_train_tfidf = tfidf.fit_transform(train_df[\"combined_input\"])\n",
        "    X_eval_tfidf = tfidf.transform(eval_df[\"combined_input\"])\n",
        "\n",
        "    # Scale features for gradient descent-based models\n",
        "    scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
        "    X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
        "    X_eval_scaled = scaler.transform(X_eval_tfidf)\n",
        "\n",
        "    # Apply SMOTE to balance the training data\n",
        "    logger.info(\"Applying SMOTE for balancing\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train_scaled, train_df[\"label\"])\n",
        "\n",
        "    logger.info(\"Original train distribution:\")\n",
        "    logger.info(train_df[\"type\"].value_counts())\n",
        "    logger.info(\"Balanced train distribution:\")\n",
        "    logger.info(pd.Series(y_train_res).map(REVERSE_LABEL_MAP).value_counts())\n",
        "\n",
        "    # Define individual models with hyperparameter tuning\n",
        "    logger.info(\"Setting up ensemble models with gradient descent optimization\")\n",
        "\n",
        "    # Logistic Regression\n",
        "    logistic = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42)\n",
        "    logistic_params = {\n",
        "        'C': [0.01, 0.1, 1, 10],\n",
        "        'max_iter': [1000, 2000, 3000],\n",
        "    }\n",
        "    logistic_search = RandomizedSearchCV(logistic, logistic_params, n_iter=5, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "\n",
        "    # Random Forest\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    rf_params = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "    rf_search = RandomizedSearchCV(rf, rf_params, n_iter=5, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "\n",
        "    # XGBoost\n",
        "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42,tree_method='gpu_hist')\n",
        "    xgb_params = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 6, 9],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "    }\n",
        "    xgb_search = RandomizedSearchCV(xgb, xgb_params, n_iter=5, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "\n",
        "    # Train all models with hyperparameter tuning\n",
        "    logger.info(\"Training Logistic Regression\")\n",
        "    logistic_search.fit(X_train_res, y_train_res)\n",
        "    logger.info(f\"Best Logistic Regression params: {logistic_search.best_params_}\")\n",
        "\n",
        "    logger.info(\"Training Random Forest\")\n",
        "    rf_search.fit(X_train_res, y_train_res)\n",
        "    logger.info(f\"Best Random Forest params: {rf_search.best_params_}\")\n",
        "\n",
        "    logger.info(\"Training XGBoost\")\n",
        "    xgb_search.fit(X_train_res, y_train_res)\n",
        "    logger.info(f\"Best XGBoost params: {xgb_search.best_params_}\")\n",
        "\n",
        "    # Create ensemble model\n",
        "    logger.info(\"Creating ensemble model\")\n",
        "    ensemble = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('logistic', logistic_search.best_estimator_),\n",
        "            ('random_forest', rf_search.best_estimator_),\n",
        "            ('xgboost', xgb_search.best_estimator_)\n",
        "        ],\n",
        "        voting='soft'  # Use soft voting for probability-based weighting\n",
        "    )\n",
        "    ensemble.fit(X_train_res, y_train_res)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    logger.info(\"Evaluating on validation set\")\n",
        "    val_preds = ensemble.predict(X_eval_scaled)\n",
        "    metrics = compute_metrics(eval_df[\"label\"], val_preds)\n",
        "    logger.info(f\"Validation metrics: {metrics}\")\n",
        "\n",
        "    # Save predictions\n",
        "    logger.info(\"Saving predictions\")\n",
        "    eval_df[\"prediction\"] = val_preds\n",
        "    eval_df[\"predicted_type\"] = eval_df[\"prediction\"].map(REVERSE_LABEL_MAP)\n",
        "    eval_df.to_csv(RESULTS_PATH, index=False)\n",
        "\n",
        "    # Save model\n",
        "    logger.info(f\"Saving model to {MODEL_PATH}\")\n",
        "    joblib.dump({\n",
        "        'model': ensemble,\n",
        "        'tfidf': tfidf,\n",
        "        'scaler': scaler,\n",
        "        'label_map': LABEL_MAP\n",
        "    }, MODEL_PATH)\n",
        "\n",
        "    logger.info(\"Pipeline completed successfully\")\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage (replace with your actual file path)\n",
        "    file_path = \"/content/drive/MyDrive/Colab Notebooks/balanced_data.xlsx\"\n",
        "    main(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model.pkl\")"
      ],
      "metadata": {
        "id": "jj9LLXFMEXrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-K0_8yJ4VNA"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf5ZRuzCfzF9",
        "outputId": "f8d950c4-31f0-4c2f-e263-2fb4830cf2bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"orange is the new black\" star yael stone is renouncing her u.s. green card to return to her native ...\n",
            "True Bias: right | Predicted: left (0.45)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: \"we have one beautiful law,\" trump recently said in his characteristically bizarre syntax and dictio...\n",
            "True Bias: left | Predicted: left (0.49)\n",
            "\n",
            "Text: ...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. white...\n",
            "True Bias: left | Predicted: left (0.46)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-bb1274230707>:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sample_rows[col] = \"\"\n",
            "<ipython-input-8-bb1274230707>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
            "<ipython-input-8-bb1274230707>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Constants\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results_opt\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model_opt.pkl\")\n",
        "TFIDF_PATH = os.path.join(OUTPUT_DIR, \"tfidf_vectorizer.pkl\")\n",
        "TEST_FILE_PATH = \"/content/drive/MyDrive/Colab Notebooks/test_sample.xlsx\"\n",
        "\n",
        "# Mount Google Drive (for Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "except ImportError:\n",
        "    logger.info(\"Not running in Colab; skipping drive mount.\")\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------- Text Processing Functions ----------------\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(str(t).lower() for t in text if isinstance(t, str)) if isinstance(text, list) else str(text).lower()\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
        "    df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
        "    return df\n",
        "\n",
        "# ---------------- Load Model and TF-IDF ----------------\n",
        "def load_model():\n",
        "    logger.info(f\"Attempting to load model from {MODEL_PATH}\")\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}\")\n",
        "\n",
        "    saved_data = joblib.load(MODEL_PATH)\n",
        "\n",
        "    if isinstance(saved_data, dict):\n",
        "        logger.info(\"Loaded dictionary format.\")\n",
        "        model = saved_data.get(\"ensemble\") or saved_data.get(\"model\")\n",
        "        tfidf = saved_data.get(\"tfidf\") or saved_data.get(\"vectorizer\")\n",
        "        if model is None or tfidf is None:\n",
        "            raise KeyError(\"Missing 'ensemble'/'model' or 'tfidf'/'vectorizer' in saved dictionary.\")\n",
        "    else:\n",
        "        logger.info(\"Loaded model object directly. Trying separate TF-IDF.\")\n",
        "        model = saved_data\n",
        "        if not os.path.exists(TFIDF_PATH):\n",
        "            raise FileNotFoundError(f\"TF-IDF vectorizer file not found at {TFIDF_PATH}\")\n",
        "        tfidf = joblib.load(TFIDF_PATH)\n",
        "\n",
        "    return model, tfidf\n",
        "\n",
        "# ---------------- Test with New Data ----------------\n",
        "def test_new_data():\n",
        "    logger.info(f\"Loading test data from {TEST_FILE_PATH}\")\n",
        "    df_test = pd.read_excel(TEST_FILE_PATH, engine='openpyxl')\n",
        "\n",
        "    logger.info(\"Columns in the test dataset:\")\n",
        "    logger.info(df_test.columns)\n",
        "\n",
        "    sample_rows = df_test.head(30)\n",
        "\n",
        "    required_cols = [\"sentence\", \"topic\", \"article\", \"biased_words\"]\n",
        "    for col in required_cols:\n",
        "        if col not in sample_rows.columns:\n",
        "            sample_rows[col] = \"\"\n",
        "    if 'type' not in sample_rows.columns:\n",
        "        sample_rows['type'] = \"Unknown\"\n",
        "\n",
        "    text_cols = [\"sentence\", \"topic\", \"article\", \"biased_words\"]\n",
        "    sample_data_processed = combine_text(sample_rows, text_cols)\n",
        "\n",
        "    ensemble, tfidf = load_model()\n",
        "\n",
        "    logger.info(\"Transforming sample data to TF-IDF features\")\n",
        "    X_sample_tfidf = tfidf.transform(sample_data_processed[\"combined_input\"])\n",
        "\n",
        "    logger.info(\"Making predictions\")\n",
        "    pred_labels = ensemble.predict(X_sample_tfidf)\n",
        "    pred_probs = ensemble.predict_proba(X_sample_tfidf)\n",
        "    confidences = np.max(pred_probs, axis=1)\n",
        "\n",
        "    for idx, (index, row) in enumerate(sample_rows.iterrows()):\n",
        "        text = row[\"sentence\"]\n",
        "        true_label = row[\"type\"]\n",
        "        readable_label = REVERSE_LABEL_MAP[pred_labels[idx]]\n",
        "        confidence = confidences[idx]\n",
        "        print(f\"\\nText: {text[:100]}...\")\n",
        "        print(f\"True Bias: {true_label} | Predicted: {readable_label} ({confidence:.2f})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_new_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chunking method"
      ],
      "metadata": {
        "id": "-4ADcPe6KGzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "vixhYgfOKPoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    logger.info(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    logger.warning(\"No GPU detected. Falling back to CPU.\")\n",
        "\n",
        "# Constants\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results_opt\"\n",
        "LOGGING_DIR = \"/content/drive/MyDrive/Colab Notebooks/logs_opt\"\n",
        "RESULTS_PATH = \"/content/drive/MyDrive/Colab Notebooks/predictions_bias.csv\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model_bias.pkl\")\n",
        "CHUNK_SIZE = 10000  # Adjust based on memory constraints\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LOGGING_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(RESULTS_PATH), exist_ok=True)\n",
        "\n",
        "# ---------------- Text Processing Functions ----------------\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(str(t).lower() for t in text if isinstance(t, str)) if isinstance(text, list) else str(text).lower()\n",
        "\n",
        "def combine_text(df, text_cols):\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].apply(preprocess_text) if col in df else \"\"\n",
        "    df[\"combined_input\"] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
        "    return df\n",
        "\n",
        "# ---------------- Load & Preprocess in Chunks ----------------\n",
        "def load_and_preprocess_chunked(file_path, chunk_size=CHUNK_SIZE):\n",
        "    logger.info(\"Loading and preprocessing data in chunks\")\n",
        "    text_cols = [\"text\", \"topic\", \"article\", \"biased_words\"]\n",
        "    chunks = []\n",
        "\n",
        "    reader = pd.read_csv(file_path,chunksize=chunk_size)\n",
        "    for i, chunk in enumerate(reader):\n",
        "        logger.info(f\"Processing chunk {i+1}\")\n",
        "        chunk = chunk[chunk[\"type\"].isin(LABEL_MAP.keys())]\n",
        "        chunk_processed = combine_text(chunk, text_cols)\n",
        "        chunk_processed[\"label\"] = chunk_processed[\"type\"].map(LABEL_MAP)\n",
        "        chunks.append(chunk_processed)\n",
        "\n",
        "    df_processed = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "    logger.info(\"Data distribution:\")\n",
        "    logger.info(df_processed[\"type\"].value_counts())\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# ---------------- Metrics ----------------\n",
        "def compute_metrics(labels, preds):\n",
        "    logger.info(\"Computing metrics\")\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# ---------------- Main Pipeline with Optimization ----------------\n",
        "def main(file_path):\n",
        "    logger.info(\"Starting main pipeline with chunked processing and GPU support\")\n",
        "    # Load and prepare data\n",
        "    df = load_and_preprocess_chunked(file_path)\n",
        "\n",
        "    # Train-Test Split\n",
        "    logger.info(\"Splitting data\")\n",
        "    train_df, eval_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "    # Create a pipeline with TF-IDF with optimized features\n",
        "    logger.info(\"Setting up pipeline with TF-IDF\")\n",
        "    tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2), min_df=5)\n",
        "\n",
        "    # Transform text to TF-IDF features\n",
        "    logger.info(\"Transforming training data to TF-IDF\")\n",
        "    X_train_tfidf = tfidf.fit_transform(train_df[\"combined_input\"])\n",
        "    X_eval_tfidf = tfidf.transform(eval_df[\"combined_input\"])\n",
        "\n",
        "    # Scale features for gradient descent-based models\n",
        "    scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
        "    X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
        "    X_eval_scaled = scaler.transform(X_eval_tfidf)\n",
        "\n",
        "    # Use original balanced data for training\n",
        "    logger.info(\"Training distribution:\")\n",
        "    logger.info(train_df[\"type\"].value_counts())\n",
        "\n",
        "    # Define individual models with hyperparameter tuning\n",
        "    logger.info(\"Setting up ensemble models with gradient descent optimization\")\n",
        "\n",
        "    # Logistic Regression\n",
        "    logistic = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42)\n",
        "    logistic_params = {\n",
        "        'C': [0.01, 0.1, 1, 10],\n",
        "        'max_iter': [1000, 2000, 3000],\n",
        "    }\n",
        "    logistic_search = RandomizedSearchCV(logistic, logistic_params, n_iter=5, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "\n",
        "    # Random Forest\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    rf_params = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "    rf_search = RandomizedSearchCV(rf, rf_params, n_iter=5, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "\n",
        "    # XGBoost with GPU support\n",
        "    xgb = XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='mlogloss',\n",
        "        random_state=42,\n",
        "        tree_method='gpu_hist',  # Explicitly use GPU\n",
        "        predictor='gpu_predictor'\n",
        "    )\n",
        "    xgb_params = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 6, 9],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "    }\n",
        "    xgb_search = RandomizedSearchCV(xgb, xgb_params, n_iter=5, cv=5, scoring='accuracy', random_state=42, n_jobs=1)\n",
        "\n",
        "    # Train all models with hyperparameter tuning\n",
        "    logger.info(\"Training Logistic Regression\")\n",
        "    logistic_search.fit(X_train_scaled, train_df[\"label\"])\n",
        "    logger.info(f\"Best Logistic Regression params: {logistic_search.best_params_}\")\n",
        "\n",
        "    logger.info(\"Training Random Forest\")\n",
        "    rf_search.fit(X_train_scaled, train_df[\"label\"])\n",
        "    logger.info(f\"Best Random Forest params: {rf_search.best_params_}\")\n",
        "\n",
        "    logger.info(\"Training XGBoost with GPU\")\n",
        "    xgb_search.fit(X_train_scaled, train_df[\"label\"])\n",
        "    logger.info(f\"Best XGBoost params: {xgb_search.best_params_}\")\n",
        "\n",
        "    # Create ensemble model\n",
        "    logger.info(\"Creating ensemble model\")\n",
        "    ensemble = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('logistic', logistic_search.best_estimator_),\n",
        "            ('random_forest', rf_search.best_estimator_),\n",
        "            ('xgboost', xgb_search.best_estimator_)\n",
        "        ],\n",
        "        voting='soft'  # Use soft voting for probability-based weighting\n",
        "    )\n",
        "    ensemble.fit(X_train_scaled, train_df[\"label\"])\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    logger.info(\"Evaluating on validation set\")\n",
        "    val_preds = ensemble.predict(X_eval_scaled)\n",
        "    metrics = compute_metrics(eval_df[\"label\"], val_preds)\n",
        "    logger.info(f\"Validation metrics: {metrics}\")\n",
        "\n",
        "    # Save predictions\n",
        "    logger.info(\"Saving predictions\")\n",
        "    eval_df[\"prediction\"] = val_preds\n",
        "    eval_df[\"predicted_type\"] = eval_df[\"prediction\"].map(REVERSE_LABEL_MAP)\n",
        "    eval_df.to_csv(RESULTS_PATH, index=False)\n",
        "\n",
        "    # Save final model\n",
        "    logger.info(f\"Saving final model to {MODEL_PATH}\")\n",
        "    joblib.dump({\n",
        "        'model': ensemble,\n",
        "        'tfidf': tfidf,\n",
        "        'scaler': scaler,\n",
        "        'label_map': LABEL_MAP\n",
        "    }, MODEL_PATH)\n",
        "\n",
        "    logger.info(\"Pipeline completed successfully\")\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage (replace with your actual file path)\n",
        "    file_path = \"/content/drive/MyDrive/Colab Notebooks/balanced_data.csv\"\n",
        "    main(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bSKXXBcRp1E",
        "outputId": "ed4feab9-f69c-4abb-aa1a-9fb1334f48f6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:11] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:15:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:16:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:17:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:19:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:19:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:20:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:20:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ---------------- Set Up Logging ----------------\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ---------------- Constants ----------------\n",
        "LABEL_MAP = {\"left\": 0, \"center\": 1, \"right\": 2}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/results_opt\"\n",
        "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ensemble_model_bias.pkl\")\n",
        "\n",
        "# ---------------- Mount Google Drive (Colab) ----------------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "except ImportError:\n",
        "    logger.info(\"Not running in Colab; skipping drive mount.\")\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------- Text Preprocessing ----------------\n",
        "def preprocess_text(text):\n",
        "    return str(text).lower()\n",
        "\n",
        "# ---------------- Load Model ----------------\n",
        "def load_model():\n",
        "    logger.info(f\"Attempting to load model and TF-IDF from {MODEL_PATH}\")\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        logger.error(f\"Model file not found at {MODEL_PATH}. Please upload the file.\")\n",
        "        raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}.\")\n",
        "\n",
        "    saved_data = joblib.load(MODEL_PATH)\n",
        "\n",
        "    ensemble = saved_data.get('model') or saved_data.get('ensemble')\n",
        "    tfidf = saved_data['tfidf']\n",
        "\n",
        "    return ensemble, tfidf\n",
        "\n",
        "# ---------------- Test Model with Raw Text ----------------\n",
        "def test_model():\n",
        "    sample_texts= [\n",
        "        [\"\"\"As wildfires rage across California, floods displace thousands in the Midwest, and heatwaves scorch cities from Texas to New York, the evidence is undeniable: the climate crisis is no longer a distant threatits here. And yet, as communities suffer and ecosystems collapse, fossil fuel corporations continue to post record-breaking profits, protected by conservative politicians and a global system rigged in their favor.\n",
        "        In 2024 alone, the five largest oil companies reported over $200 billion in profits. Instead of investing in renewable energy or helping vulnerable communities transition to a green economy, these corporations funneled billions into stock buybacks and executive bonuses. Their message is clear: profits come before people, and the planet can burn so long as the shareholders stay rich.\n",
        "        Even more alarming is the political shielding they receive from right-wing lawmakers, many of whom deny climate science altogether. Republican leaders in Congress have repeatedly blocked climate legislation, gutted the Environmental Protection Agencys regulatory powers, and prioritized drilling permits over clean air and water.\n",
        "        Meanwhile, climate activistsmany of them youth, Indigenous leaders, and marginalized communitiescontinue to face police repression, surveillance, and criminalization. Peaceful protesters at pipeline sites are arrested, while oil spills and environmental destruction go unpunished.\n",
        "        We need a Green New Deal-level transformation: bold investments in wind, solar, and green infrastructure; the creation of millions of unionized green jobs; and climate reparations for communities hit hardest by pollution and environmental racism.\n",
        "        The time for delay is over. The time to act is now.\"\"\"\n",
        "        ],\n",
        "        [\"\"\"The United States thrives when government steps back and lets free enterprise lead. In recent years, however, progressive lawmakers have increasingly pushed for regulation, redistribution, and intervention that stifles innovation and discourages hard work.\n",
        "        From overreaching environmental mandates to government-controlled healthcare proposals, the left continues to champion policies that prioritize bureaucracy over results. These moves are not only anti-businesstheyre anti-American.\n",
        "        America's economic engine runs best when the private sector is free to create, compete, and grow. Small business owners across the country are already struggling with inflation and labor shortagesproblems worsened by excessive government interference and rising taxes.\n",
        "        We must return to policies that reward productivity, protect property rights, and uphold free-market values. Deregulation, tax reform, and energy independence will not only restore our economytheyll renew our national spirit.\n",
        "        \"\"\"],\n",
        "        [\"\"\"As artificial intelligence tools become increasingly integrated into everyday lifefrom health diagnostics to criminal justice systemsDemocratic and Republican lawmakers alike are recognizing the need for clear regulatory frameworks.\n",
        "        A bipartisan group in Congress recently introduced the American AI Responsibility Act, aiming to address transparency, data privacy, and algorithmic bias. While the bill doesnt go as far as some activists demand, it marks an important step toward balancing innovation with accountability.\n",
        "        Tech CEOs have expressed cautious support, stating that some regulation is needed to maintain public trust, but they warn against overregulation that could drive development offshore.\n",
        "        Experts agree: regulation must be careful, measured, and informed by the sciencenot by political theater. While divisions remain, the shared concern over AIs risks may offer a rare opportunity for consensus in Washington.\n",
        "        \"\"\"],\n",
        "        [\"\"\"In yet another blow to working-class Americans, Senate Republicans have blocked legislation that would raise the federal minimum wage to $17 per hour by 2027. With wages stagnant and inflation hitting food, rent, and transportation costs, the move is being widely condemned by labor leaders and economists.\n",
        "        The current $7.25 minimum wage has not been raised since 2009, despite historic gains in productivity and corporate profits. Over 60% of Americans support a raise, but Republican lawmakers claim it would hurt small businessesan argument that many economists say is overblown.\n",
        "        In reality, the refusal to raise wages preserves exploitative systems where billion-dollar corporations rely on underpaid workers while CEO salaries skyrocket.\n",
        "        This is not just about economicsits about dignity. Every American who works full-time should be able to afford basic necessities. Congresss failure to act is a moral failure, and its up to voters to hold them accountable.\"\"\"],\n",
        "        [\"\"\"The southern border has long been a flashpoint in American politics, but recent data shows that tougher enforcement and advanced surveillance technology are yielding results. Illegal crossings dropped 30% in the first quarter of 2025 compared to the previous year, according to Homeland Security reports.\n",
        "        Under the new measures, authorities have deployed AI-powered drones, reinforced border fencing, and accelerated asylum screening procedures. Critics on the left say the policies are inhumane, but officials argue they are necessary to protect national sovereignty and public safety.\n",
        "        Drug seizures have also increased, particularly fentanyl shipments originating from cartels that exploit weak border points. Law enforcement agencies say the new tools and funding are making a significant impact.\n",
        "        The Biden administration was slow to act early in its term, but this policy shift marks a necessary correction. The right to immigrate must be balanced with the rule of lawand American citizens deserve to feel safe and secure in their own country.\n",
        "        \"\"\"]\n",
        "        ]\n",
        "\n",
        "    # Load model and TF-IDF\n",
        "    ensemble, tfidf = load_model()\n",
        "\n",
        "    # Process and predict\n",
        "    for text in sample_texts:\n",
        "        processed_text = preprocess_text(text)\n",
        "        tfidf_input = tfidf.transform([processed_text])\n",
        "\n",
        "        predicted_label = ensemble.predict(tfidf_input)[0]\n",
        "        predicted_proba = ensemble.predict_proba(tfidf_input)[0]\n",
        "        confidence = np.max(predicted_proba)\n",
        "\n",
        "        readable_label = REVERSE_LABEL_MAP[predicted_label]\n",
        "\n",
        "        print(f\"\\nText: {text[:100]}...\")\n",
        "        print(f\"Predicted Bias: {readable_label} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "# ---------------- Main Execution ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    test_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXNFsgkJl17O",
        "outputId": "699a2c64-12e4-4140-da1f-2ad8b6a4164f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:30:15] WARNING: /workspace/src/gbm/gbtree.cc:363: \n",
            "  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
            "  machine. Consider using `save_model/load_model` instead. See:\n",
            "\n",
            "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
            "\n",
            "  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:30:15] WARNING: /workspace/src/gbm/gbtree.cc:388: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:30:15] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:30:15] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: ['As wildfires rage across California, floods displace thousands in the Midwest, and heatwaves scorch cities from Texas to New York, the evidence is undeniable: the climate crisis is no longer a distant threatits here. And yet, as communities suffer and ecosystems collapse, fossil fuel corporations continue to post record-breaking profits, protected by conservative politicians and a global system rigged in their favor.\\n        In 2024 alone, the five largest oil companies reported over $200 billion in profits. Instead of investing in renewable energy or helping vulnerable communities transition to a green economy, these corporations funneled billions into stock buybacks and executive bonuses. Their message is clear: profits come before people, and the planet can burn so long as the shareholders stay rich.\\n        Even more alarming is the political shielding they receive from right-wing lawmakers, many of whom deny climate science altogether. Republican leaders in Congress have repeatedly blocked climate legislation, gutted the Environmental Protection Agencys regulatory powers, and prioritized drilling permits over clean air and water.\\n        Meanwhile, climate activistsmany of them youth, Indigenous leaders, and marginalized communitiescontinue to face police repression, surveillance, and criminalization. Peaceful protesters at pipeline sites are arrested, while oil spills and environmental destruction go unpunished.\\n        We need a Green New Deal-level transformation: bold investments in wind, solar, and green infrastructure; the creation of millions of unionized green jobs; and climate reparations for communities hit hardest by pollution and environmental racism.\\n        The time for delay is over. The time to act is now.']...\n",
            "Predicted Bias: center (Confidence: 0.56)\n",
            "\n",
            "Text: [\"The United States thrives when government steps back and lets free enterprise lead. In recent years, however, progressive lawmakers have increasingly pushed for regulation, redistribution, and intervention that stifles innovation and discourages hard work.\\n        From overreaching environmental mandates to government-controlled healthcare proposals, the left continues to champion policies that prioritize bureaucracy over results. These moves are not only anti-businesstheyre anti-American.\\n        America's economic engine runs best when the private sector is free to create, compete, and grow. Small business owners across the country are already struggling with inflation and labor shortagesproblems worsened by excessive government interference and rising taxes.\\n        We must return to policies that reward productivity, protect property rights, and uphold free-market values. Deregulation, tax reform, and energy independence will not only restore our economytheyll renew our national spirit.\\n        \"]...\n",
            "Predicted Bias: left (Confidence: 0.60)\n",
            "\n",
            "Text: ['As artificial intelligence tools become increasingly integrated into everyday lifefrom health diagnostics to criminal justice systemsDemocratic and Republican lawmakers alike are recognizing the need for clear regulatory frameworks.\\n        A bipartisan group in Congress recently introduced the American AI Responsibility Act, aiming to address transparency, data privacy, and algorithmic bias. While the bill doesnt go as far as some activists demand, it marks an important step toward balancing innovation with accountability.\\n        Tech CEOs have expressed cautious support, stating that some regulation is needed to maintain public trust, but they warn against overregulation that could drive development offshore.\\n        Experts agree: regulation must be careful, measured, and informed by the sciencenot by political theater. While divisions remain, the shared concern over AIs risks may offer a rare opportunity for consensus in Washington.\\n        ']...\n",
            "Predicted Bias: left (Confidence: 0.57)\n",
            "\n",
            "Text: ['In yet another blow to working-class Americans, Senate Republicans have blocked legislation that would raise the federal minimum wage to $17 per hour by 2027. With wages stagnant and inflation hitting food, rent, and transportation costs, the move is being widely condemned by labor leaders and economists.\\n        The current $7.25 minimum wage has not been raised since 2009, despite historic gains in productivity and corporate profits. Over 60% of Americans support a raise, but Republican lawmakers claim it would hurt small businessesan argument that many economists say is overblown.\\n        In reality, the refusal to raise wages preserves exploitative systems where billion-dollar corporations rely on underpaid workers while CEO salaries skyrocket.\\n        This is not just about economicsits about dignity. Every American who works full-time should be able to afford basic necessities. Congresss failure to act is a moral failure, and its up to voters to hold them accountable.']...\n",
            "Predicted Bias: left (Confidence: 0.52)\n",
            "\n",
            "Text: ['The southern border has long been a flashpoint in American politics, but recent data shows that tougher enforcement and advanced surveillance technology are yielding results. Illegal crossings dropped 30% in the first quarter of 2025 compared to the previous year, according to Homeland Security reports.\\n        Under the new measures, authorities have deployed AI-powered drones, reinforced border fencing, and accelerated asylum screening procedures. Critics on the left say the policies are inhumane, but officials argue they are necessary to protect national sovereignty and public safety.\\n        Drug seizures have also increased, particularly fentanyl shipments originating from cartels that exploit weak border points. Law enforcement agencies say the new tools and funding are making a significant impact.\\n        The Biden administration was slow to act early in its term, but this policy shift marks a necessary correction. The right to immigrate must be balanced with the rule of lawand American citizens deserve to feel safe and secure in their own country.\\n        ']...\n",
            "Predicted Bias: left (Confidence: 0.62)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}